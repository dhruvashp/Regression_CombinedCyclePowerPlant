{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         AT      V       AP     RH      PE\n",
      "0     14.96  41.76  1024.07  73.17  463.26\n",
      "1     25.18  62.96  1020.04  59.08  444.37\n",
      "2      5.11  39.40  1012.16  92.14  488.56\n",
      "3     20.86  57.32  1010.24  76.64  446.48\n",
      "4     10.82  37.50  1009.23  96.62  473.90\n",
      "...     ...    ...      ...    ...     ...\n",
      "9563  16.65  49.69  1014.01  91.00  460.03\n",
      "9564  13.19  39.18  1023.67  66.78  469.62\n",
      "9565  31.32  74.33  1012.92  36.48  429.57\n",
      "9566  24.48  69.45  1013.86  62.39  435.74\n",
      "9567  21.60  62.52  1017.23  67.87  453.28\n",
      "\n",
      "[9568 rows x 5 columns]\n",
      "         AT      V       AP     RH\n",
      "0     14.96  41.76  1024.07  73.17\n",
      "1     25.18  62.96  1020.04  59.08\n",
      "2      5.11  39.40  1012.16  92.14\n",
      "3     20.86  57.32  1010.24  76.64\n",
      "4     10.82  37.50  1009.23  96.62\n",
      "...     ...    ...      ...    ...\n",
      "9563  16.65  49.69  1014.01  91.00\n",
      "9564  13.19  39.18  1023.67  66.78\n",
      "9565  31.32  74.33  1012.92  36.48\n",
      "9566  24.48  69.45  1013.86  62.39\n",
      "9567  21.60  62.52  1017.23  67.87\n",
      "\n",
      "[9568 rows x 4 columns]\n",
      "0       463.26\n",
      "1       444.37\n",
      "2       488.56\n",
      "3       446.48\n",
      "4       473.90\n",
      "         ...  \n",
      "9563    460.03\n",
      "9564    469.62\n",
      "9565    429.57\n",
      "9566    435.74\n",
      "9567    453.28\n",
      "Name: PE, Length: 9568, dtype: float64\n",
      "[467.26978996 444.0773659  483.56264263 ... 432.40579787 443.03667582\n",
      " 449.69603741]\n",
      "MSE for multi-regression model is : \n",
      " 20.767397532535018\n",
      "Beta 0 for this regression is : \n",
      " 454.6092743153102\n",
      "Other Beta for this regression are : \n",
      " [-1.97751311 -0.23391642  0.06208294 -0.1580541 ]\n",
      "Beta for AT is : \n",
      " -1.9775131066353961\n",
      "Beta for V is : \n",
      " -0.2339164225824992\n",
      "Beta for AP is : \n",
      " 0.06208294378085628\n",
      "Beta for RH is : \n",
      " -0.15805410291641417\n",
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                     PE   R-squared:                       0.929\n",
      "Model:                            OLS   Adj. R-squared:                  0.929\n",
      "Method:                 Least Squares   F-statistic:                 3.114e+04\n",
      "Date:                Sun, 11 Oct 2020   Prob (F-statistic):               0.00\n",
      "Time:                        21:41:19   Log-Likelihood:                -28088.\n",
      "No. Observations:                9568   AIC:                         5.619e+04\n",
      "Df Residuals:                    9563   BIC:                         5.622e+04\n",
      "Df Model:                           4                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const        454.6093      9.749     46.634      0.000     435.500     473.718\n",
      "AT            -1.9775      0.015   -129.342      0.000      -2.007      -1.948\n",
      "V             -0.2339      0.007    -32.122      0.000      -0.248      -0.220\n",
      "AP             0.0621      0.009      6.564      0.000       0.044       0.081\n",
      "RH            -0.1581      0.004    -37.918      0.000      -0.166      -0.150\n",
      "==============================================================================\n",
      "Omnibus:                      892.002   Durbin-Watson:                   2.033\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             4086.777\n",
      "Skew:                          -0.352   Prob(JB):                         0.00\n",
      "Kurtosis:                       6.123   Cond. No.                     2.13e+05\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The condition number is large, 2.13e+05. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n",
      "The reference t-value is : \n",
      " 1.9602120830871699\n",
      "The reference F-statistic (degree of freedom (4,9563) and alpha 0.05) value is : \n",
      "2.3728 (using an online calculator)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nSummary\\n\\nUsing all predictors gives us a lower MSE than using just one\\n\\nThe null hypothesis can be rejected for all predictors using t-test\\n\\nThe null hypothesis (\"ALL beta\\'s are null\") can be rejected using F-test\\n\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Thu Sep 24 10:46:34 2020\n",
    "\n",
    "@author: DHRUV\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "HW2\n",
    "\n",
    "d\n",
    "\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import math \n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from scipy import stats\n",
    "import statsmodels.api as sm\n",
    "\n",
    "df = pd.read_csv('Power_Plant.csv')\n",
    "print(df)\n",
    "\n",
    "X = df.iloc[:,0:4]\n",
    "y = df.iloc[:,4]\n",
    "\n",
    "print(X)\n",
    "print(y)\n",
    "\n",
    "reg = LinearRegression()\n",
    "reg.fit(X,y)\n",
    "y_predicted = reg.predict(X)\n",
    "print(y_predicted)\n",
    "MSE = mean_squared_error(y,y_predicted)\n",
    "print('MSE for multi-regression model is : \\n', MSE)\n",
    "\n",
    "\"\"\"\n",
    "As can be seen the MSE of the multi-regression model using all the predictors in obtained\n",
    "to be 20.76, less than that obtained by any of the single predictor based regression models\n",
    "\n",
    "Thus, multi-regression model seems to fit the data much better, as seen from the MSE perspective\n",
    "\n",
    "The performance under MSE is only for MSE-Training, as we've used the entire dataset for the\n",
    "training purpose\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\"\"\"\n",
    "Null Hypothesis Test for the predictors\n",
    "\"\"\"\n",
    "\n",
    "beta0 = reg.intercept_\n",
    "beta = reg.coef_\n",
    "\n",
    "print('Beta 0 for this regression is : \\n', beta0)\n",
    "print('Other Beta for this regression are : \\n', beta)\n",
    "\n",
    "beta_AT = beta[0]\n",
    "beta_V = beta[1]\n",
    "beta_AP = beta[2]\n",
    "beta_RH = beta[3]\n",
    "\n",
    "print('Beta for AT is : \\n', beta_AT)\n",
    "print('Beta for V is : \\n', beta_V)\n",
    "print('Beta for AP is : \\n', beta_AP)\n",
    "print('Beta for RH is : \\n', beta_RH)\n",
    "\n",
    "\"\"\"\n",
    "The calculation of various t-statistics can be manually done similar to how it was done in\n",
    "HW2_c file for each variable. Using that p-value can be quite easily obtained and then \n",
    "either of the two hypothesis tests can be performed. \n",
    "\n",
    "However rather than elongating the code, code that would be repeated from HW2_c file, I've used\n",
    "statsmodels to obtain the t-values, p-values and the F-statistic.\n",
    "\n",
    "It's been assumed that in-built libraries can be used\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "X_sm = sm.add_constant(X)      \n",
    "est = sm.OLS(y, X_sm)\n",
    "est_data = est.fit()\n",
    "print(est_data.summary())\n",
    "\n",
    "t_reference = stats.t.ppf(1-0.025, 9563)\n",
    "print('The reference t-value is : \\n', t_reference)\n",
    "print('The reference F-statistic (degree of freedom (4,9563) and alpha 0.05) value is : \\n2.3728 (using an online calculator)')\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "t-test and p-values\n",
    "\n",
    "From either the t-test or the p-values, it can be quite easily seen that all the\n",
    "predictors are relevant.\n",
    "\n",
    "Thus the null hypothesis can be rejected for all the predictors and all the predictors \n",
    "can be called statistically relevant\n",
    "\n",
    "F-test\n",
    "\n",
    "From the F-test the F-value obtained is much larger than the reference F calculated via an \n",
    "online calculator. Thus we can say that at least one of the predictors is relevant and that \n",
    "we can reject the hypothesis : \"ALL the beta's are null\". Thus we do have some linear relationship\n",
    "between the prediction and the predictor in line with the actual data.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\"\"\"\n",
    "Summary\n",
    "\n",
    "Using all predictors gives us a lower MSE than using just one\n",
    "\n",
    "The null hypothesis can be rejected for all predictors using t-test\n",
    "\n",
    "The null hypothesis (\"ALL beta's are null\") can be rejected using F-test\n",
    "\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
