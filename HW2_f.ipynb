{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         AT      V       AP     RH      PE\n",
      "0     14.96  41.76  1024.07  73.17  463.26\n",
      "1     25.18  62.96  1020.04  59.08  444.37\n",
      "2      5.11  39.40  1012.16  92.14  488.56\n",
      "3     20.86  57.32  1010.24  76.64  446.48\n",
      "4     10.82  37.50  1009.23  96.62  473.90\n",
      "...     ...    ...      ...    ...     ...\n",
      "9563  16.65  49.69  1014.01  91.00  460.03\n",
      "9564  13.19  39.18  1023.67  66.78  469.62\n",
      "9565  31.32  74.33  1012.92  36.48  429.57\n",
      "9566  24.48  69.45  1013.86  62.39  435.74\n",
      "9567  21.60  62.52  1017.23  67.87  453.28\n",
      "\n",
      "[9568 rows x 5 columns]\n",
      "0       463.26\n",
      "1       444.37\n",
      "2       488.56\n",
      "3       446.48\n",
      "4       473.90\n",
      "         ...  \n",
      "9563    460.03\n",
      "9564    469.62\n",
      "9565    429.57\n",
      "9566    435.74\n",
      "9567    453.28\n",
      "Name: PE, Length: 9568, dtype: float64\n",
      "         AT\n",
      "0     14.96\n",
      "1     25.18\n",
      "2      5.11\n",
      "3     20.86\n",
      "4     10.82\n",
      "...     ...\n",
      "9563  16.65\n",
      "9564  13.19\n",
      "9565  31.32\n",
      "9566  24.48\n",
      "9567  21.60\n",
      "\n",
      "[9568 rows x 1 columns]\n",
      "[[1.00000000e+00 1.49600000e+01 2.23801600e+02 3.34807194e+03]\n",
      " [1.00000000e+00 2.51800000e+01 6.34032400e+02 1.59649358e+04]\n",
      " [1.00000000e+00 5.11000000e+00 2.61121000e+01 1.33432831e+02]\n",
      " ...\n",
      " [1.00000000e+00 3.13200000e+01 9.80942400e+02 3.07231160e+04]\n",
      " [1.00000000e+00 2.44800000e+01 5.99270400e+02 1.46701394e+04]\n",
      " [1.00000000e+00 2.16000000e+01 4.66560000e+02 1.00776960e+04]]\n",
      "        0      1         2             3\n",
      "0     1.0  14.96  223.8016   3348.071936\n",
      "1     1.0  25.18  634.0324  15964.935832\n",
      "2     1.0   5.11   26.1121    133.432831\n",
      "3     1.0  20.86  435.1396   9077.012056\n",
      "4     1.0  10.82  117.0724   1266.723368\n",
      "...   ...    ...       ...           ...\n",
      "9563  1.0  16.65  277.2225   4615.754625\n",
      "9564  1.0  13.19  173.9761   2294.744759\n",
      "9565  1.0  31.32  980.9424  30723.115968\n",
      "9566  1.0  24.48  599.2704  14670.139392\n",
      "9567  1.0  21.60  466.5600  10077.696000\n",
      "\n",
      "[9568 rows x 4 columns]\n",
      "          1         2             3\n",
      "0     14.96  223.8016   3348.071936\n",
      "1     25.18  634.0324  15964.935832\n",
      "2      5.11   26.1121    133.432831\n",
      "3     20.86  435.1396   9077.012056\n",
      "4     10.82  117.0724   1266.723368\n",
      "...     ...       ...           ...\n",
      "9563  16.65  277.2225   4615.754625\n",
      "9564  13.19  173.9761   2294.744759\n",
      "9565  31.32  980.9424  30723.115968\n",
      "9566  24.48  599.2704  14670.139392\n",
      "9567  21.60  466.5600  10077.696000\n",
      "\n",
      "[9568 rows x 3 columns]\n",
      "         AT       AT2           AT3\n",
      "0     14.96  223.8016   3348.071936\n",
      "1     25.18  634.0324  15964.935832\n",
      "2      5.11   26.1121    133.432831\n",
      "3     20.86  435.1396   9077.012056\n",
      "4     10.82  117.0724   1266.723368\n",
      "...     ...       ...           ...\n",
      "9563  16.65  277.2225   4615.754625\n",
      "9564  13.19  173.9761   2294.744759\n",
      "9565  31.32  980.9424  30723.115968\n",
      "9566  24.48  599.2704  14670.139392\n",
      "9567  21.60  466.5600  10077.696000\n",
      "\n",
      "[9568 rows x 3 columns]\n",
      "The predicted vector y of output from this new model of AT is : \n",
      "       y_predicted\n",
      "0      464.546844\n",
      "1      440.721819\n",
      "2      486.698569\n",
      "3      449.823419\n",
      "4      474.862273\n",
      "...           ...\n",
      "9563   460.221229\n",
      "9564   469.044734\n",
      "9565   433.038558\n",
      "9566   442.035726\n",
      "9567   448.116553\n",
      "\n",
      "[9568 rows x 1 columns]\n",
      "The mean squared error (MSE) of y for AT under this new polynomial feature model is : \n",
      " 25.66433968146689\n",
      "The intercept term for AT is : \n",
      " 492.7281433373415\n",
      "The coefficients of AT, AT2, AT3, respectively in an array is : \n",
      " [-0.61034571 -0.12513818  0.00267485]\n",
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                     PE   R-squared:                       0.912\n",
      "Model:                            OLS   Adj. R-squared:                  0.912\n",
      "Method:                 Least Squares   F-statistic:                 3.299e+04\n",
      "Date:                Sun, 11 Oct 2020   Prob (F-statistic):               0.00\n",
      "Time:                        21:48:17   Log-Likelihood:                -29101.\n",
      "No. Observations:                9568   AIC:                         5.821e+04\n",
      "Df Residuals:                    9564   BIC:                         5.824e+04\n",
      "Df Model:                           3                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const        492.7281      0.673    732.248      0.000     491.409     494.047\n",
      "AT            -0.6103      0.124     -4.941      0.000      -0.852      -0.368\n",
      "AT2           -0.1251      0.007    -18.199      0.000      -0.139      -0.112\n",
      "AT3            0.0027      0.000     22.594      0.000       0.002       0.003\n",
      "==============================================================================\n",
      "Omnibus:                      648.041   Durbin-Watson:                   2.033\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             2767.059\n",
      "Skew:                          -0.191   Prob(JB):                         0.00\n",
      "Kurtosis:                       5.607   Cond. No.                     1.90e+05\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The condition number is large, 1.9e+05. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n",
      "The reference value of t-statistic is : \n",
      " 1.9602120571430655\n",
      "The reference value of F-statistic (3,9564,0.05) is, from an online calculator : \n",
      " 2.6058\n",
      "          V\n",
      "0     41.76\n",
      "1     62.96\n",
      "2     39.40\n",
      "3     57.32\n",
      "4     37.50\n",
      "...     ...\n",
      "9563  49.69\n",
      "9564  39.18\n",
      "9565  74.33\n",
      "9566  69.45\n",
      "9567  62.52\n",
      "\n",
      "[9568 rows x 1 columns]\n",
      "[[1.00000000e+00 4.17600000e+01 1.74389760e+03 7.28251638e+04]\n",
      " [1.00000000e+00 6.29600000e+01 3.96396160e+03 2.49571022e+05]\n",
      " [1.00000000e+00 3.94000000e+01 1.55236000e+03 6.11629840e+04]\n",
      " ...\n",
      " [1.00000000e+00 7.43300000e+01 5.52494890e+03 4.10669452e+05]\n",
      " [1.00000000e+00 6.94500000e+01 4.82330250e+03 3.34978359e+05]\n",
      " [1.00000000e+00 6.25200000e+01 3.90875040e+03 2.44375075e+05]]\n",
      "        0      1          2              3\n",
      "0     1.0  41.76  1743.8976   72825.163776\n",
      "1     1.0  62.96  3963.9616  249571.022336\n",
      "2     1.0  39.40  1552.3600   61162.984000\n",
      "3     1.0  57.32  3285.5824  188329.583168\n",
      "4     1.0  37.50  1406.2500   52734.375000\n",
      "...   ...    ...        ...            ...\n",
      "9563  1.0  49.69  2469.0961  122689.385209\n",
      "9564  1.0  39.18  1535.0724   60144.136632\n",
      "9565  1.0  74.33  5524.9489  410669.451737\n",
      "9566  1.0  69.45  4823.3025  334978.358625\n",
      "9567  1.0  62.52  3908.7504  244375.075008\n",
      "\n",
      "[9568 rows x 4 columns]\n",
      "          1          2              3\n",
      "0     41.76  1743.8976   72825.163776\n",
      "1     62.96  3963.9616  249571.022336\n",
      "2     39.40  1552.3600   61162.984000\n",
      "3     57.32  3285.5824  188329.583168\n",
      "4     37.50  1406.2500   52734.375000\n",
      "...     ...        ...            ...\n",
      "9563  49.69  2469.0961  122689.385209\n",
      "9564  39.18  1535.0724   60144.136632\n",
      "9565  74.33  5524.9489  410669.451737\n",
      "9566  69.45  4823.3025  334978.358625\n",
      "9567  62.52  3908.7504  244375.075008\n",
      "\n",
      "[9568 rows x 3 columns]\n",
      "          V         V2             V3\n",
      "0     41.76  1743.8976   72825.163776\n",
      "1     62.96  3963.9616  249571.022336\n",
      "2     39.40  1552.3600   61162.984000\n",
      "3     57.32  3285.5824  188329.583168\n",
      "4     37.50  1406.2500   52734.375000\n",
      "...     ...        ...            ...\n",
      "9563  49.69  2469.0961  122689.385209\n",
      "9564  39.18  1535.0724   60144.136632\n",
      "9565  74.33  5524.9489  410669.451737\n",
      "9566  69.45  4823.3025  334978.358625\n",
      "9567  62.52  3908.7504  244375.075008\n",
      "\n",
      "[9568 rows x 3 columns]\n",
      "The predicted vector y of output from this new model of V is : \n",
      "       y_predicted\n",
      "0      469.652283\n",
      "1      441.917101\n",
      "2      473.665622\n",
      "3      447.623124\n",
      "4      477.003787\n",
      "...           ...\n",
      "9563   457.380039\n",
      "9564   474.047384\n",
      "9565   434.946408\n",
      "9566   437.144398\n",
      "9567   442.312263\n",
      "\n",
      "[9568 rows x 1 columns]\n",
      "The mean squared error (MSE) of y for V under this new polynomial feature model is : \n",
      " 65.5252708556221\n",
      "The intercept term for V is : \n",
      " 554.146849063437\n",
      "The coefficients of V, V2, V3, respectively in an array is : \n",
      " [-2.14437732e+00 -2.71228490e-03  1.34357110e-04]\n",
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                     PE   R-squared:                       0.775\n",
      "Model:                            OLS   Adj. R-squared:                  0.775\n",
      "Method:                 Least Squares   F-statistic:                 1.098e+04\n",
      "Date:                Sun, 11 Oct 2020   Prob (F-statistic):               0.00\n",
      "Time:                        21:48:17   Log-Likelihood:                -33585.\n",
      "No. Observations:                9568   AIC:                         6.718e+04\n",
      "Df Residuals:                    9564   BIC:                         6.721e+04\n",
      "Df Model:                           3                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const        554.1468      9.151     60.557      0.000     536.209     572.084\n",
      "V             -2.1444      0.509     -4.214      0.000      -3.142      -1.147\n",
      "V2            -0.0027      0.009     -0.294      0.768      -0.021       0.015\n",
      "V3             0.0001   5.45e-05      2.465      0.014    2.75e-05       0.000\n",
      "==============================================================================\n",
      "Omnibus:                      160.101   Durbin-Watson:                   2.009\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              279.778\n",
      "Skew:                          -0.125   Prob(JB):                     1.77e-61\n",
      "Kurtosis:                       3.800   Cond. No.                     2.47e+07\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The condition number is large, 2.47e+07. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n",
      "The reference value of t-statistic is : \n",
      " 1.9602120571430655\n",
      "The reference value of F-statistic (3,9564,0.05) is, from an online calculator : \n",
      " 2.6058\n",
      "           AP\n",
      "0     1024.07\n",
      "1     1020.04\n",
      "2     1012.16\n",
      "3     1010.24\n",
      "4     1009.23\n",
      "...       ...\n",
      "9563  1014.01\n",
      "9564  1023.67\n",
      "9565  1012.92\n",
      "9566  1013.86\n",
      "9567  1017.23\n",
      "\n",
      "[9568 rows x 1 columns]\n",
      "[[1.00000000e+00 1.02407000e+03 1.04871936e+06 1.07396204e+09]\n",
      " [1.00000000e+00 1.02004000e+03 1.04048160e+06 1.06133285e+09]\n",
      " [1.00000000e+00 1.01216000e+03 1.02446787e+06 1.03692539e+09]\n",
      " ...\n",
      " [1.00000000e+00 1.01292000e+03 1.02600693e+06 1.03926294e+09]\n",
      " [1.00000000e+00 1.01386000e+03 1.02791210e+06 1.04215896e+09]\n",
      " [1.00000000e+00 1.01723000e+03 1.03475687e+06 1.05258573e+09]]\n",
      "        0        1             2             3\n",
      "0     1.0  1024.07  1.048719e+06  1.073962e+09\n",
      "1     1.0  1020.04  1.040482e+06  1.061333e+09\n",
      "2     1.0  1012.16  1.024468e+06  1.036925e+09\n",
      "3     1.0  1010.24  1.020585e+06  1.031036e+09\n",
      "4     1.0  1009.23  1.018545e+06  1.027946e+09\n",
      "...   ...      ...           ...           ...\n",
      "9563  1.0  1014.01  1.028216e+06  1.042622e+09\n",
      "9564  1.0  1023.67  1.047900e+06  1.072704e+09\n",
      "9565  1.0  1012.92  1.026007e+06  1.039263e+09\n",
      "9566  1.0  1013.86  1.027912e+06  1.042159e+09\n",
      "9567  1.0  1017.23  1.034757e+06  1.052586e+09\n",
      "\n",
      "[9568 rows x 4 columns]\n",
      "            1             2             3\n",
      "0     1024.07  1.048719e+06  1.073962e+09\n",
      "1     1020.04  1.040482e+06  1.061333e+09\n",
      "2     1012.16  1.024468e+06  1.036925e+09\n",
      "3     1010.24  1.020585e+06  1.031036e+09\n",
      "4     1009.23  1.018545e+06  1.027946e+09\n",
      "...       ...           ...           ...\n",
      "9563  1014.01  1.028216e+06  1.042622e+09\n",
      "9564  1023.67  1.047900e+06  1.072704e+09\n",
      "9565  1012.92  1.026007e+06  1.039263e+09\n",
      "9566  1013.86  1.027912e+06  1.042159e+09\n",
      "9567  1017.23  1.034757e+06  1.052586e+09\n",
      "\n",
      "[9568 rows x 3 columns]\n",
      "           AP           AP2           AP3\n",
      "0     1024.07  1.048719e+06  1.073962e+09\n",
      "1     1020.04  1.040482e+06  1.061333e+09\n",
      "2     1012.16  1.024468e+06  1.036925e+09\n",
      "3     1010.24  1.020585e+06  1.031036e+09\n",
      "4     1009.23  1.018545e+06  1.027946e+09\n",
      "...       ...           ...           ...\n",
      "9563  1014.01  1.028216e+06  1.042622e+09\n",
      "9564  1023.67  1.047900e+06  1.072704e+09\n",
      "9565  1012.92  1.026007e+06  1.039263e+09\n",
      "9566  1013.86  1.027912e+06  1.042159e+09\n",
      "9567  1017.23  1.034757e+06  1.052586e+09\n",
      "\n",
      "[9568 rows x 3 columns]\n",
      "[[1.00000000e+00 1.02407000e+03 1.04871936e+06 1.07396204e+09]\n",
      " [1.00000000e+00 1.02004000e+03 1.04048160e+06 1.06133285e+09]\n",
      " [1.00000000e+00 1.01216000e+03 1.02446787e+06 1.03692539e+09]\n",
      " ...\n",
      " [1.00000000e+00 1.01292000e+03 1.02600693e+06 1.03926294e+09]\n",
      " [1.00000000e+00 1.01386000e+03 1.02791210e+06 1.04215896e+09]\n",
      " [1.00000000e+00 1.01723000e+03 1.03475687e+06 1.05258573e+09]]\n",
      "The predicted vector y of output from this new model of AP is : \n",
      "       y_predicted\n",
      "0      472.181143\n",
      "1      464.456540\n",
      "2      451.873944\n",
      "3      449.307142\n",
      "4      448.034575\n",
      "...           ...\n",
      "9563   454.531074\n",
      "9564   471.375000\n",
      "9565   452.943622\n",
      "9566   454.308883\n",
      "9567   459.589267\n",
      "\n",
      "[9568 rows x 1 columns]\n",
      "The mean squared error (MSE) of y for AP under this new polynomial feature model is : \n",
      " 211.19742224765574\n",
      "The intercept term for AP, along with coefficients of AP, AP2, AP3, respectively in an array is : \n",
      " const     0.074694\n",
      "AP       25.255593\n",
      "AP2      -0.049952\n",
      "AP3       0.000025\n",
      "dtype: float64\n",
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                     PE   R-squared:                       0.275\n",
      "Model:                            OLS   Adj. R-squared:                  0.275\n",
      "Method:                 Least Squares   F-statistic:                     1813.\n",
      "Date:                Sun, 11 Oct 2020   Prob (F-statistic):               0.00\n",
      "Time:                        21:48:17   Log-Likelihood:                -39184.\n",
      "No. Observations:                9568   AIC:                         7.837e+04\n",
      "Df Residuals:                    9565   BIC:                         7.840e+04\n",
      "Df Model:                           2                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const          0.0747      0.009      8.415      0.000       0.057       0.092\n",
      "AP            25.2556      3.001      8.415      0.000      19.372      31.139\n",
      "AP2           -0.0500      0.006     -8.439      0.000      -0.062      -0.038\n",
      "AP3         2.514e-05   2.92e-06      8.613      0.000    1.94e-05    3.09e-05\n",
      "==============================================================================\n",
      "Omnibus:                      556.766   Durbin-Watson:                   1.997\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              640.319\n",
      "Skew:                           0.621   Prob(JB):                    9.05e-140\n",
      "Kurtosis:                       2.751   Cond. No.                     2.12e+15\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The condition number is large, 2.12e+15. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n",
      "The reference value of t-statistic is : \n",
      " 1.9602120571430655\n",
      "The reference value of F-statistic (3,9564,0.05) is, from an online calculator : \n",
      " 2.6058\n",
      "         RH\n",
      "0     73.17\n",
      "1     59.08\n",
      "2     92.14\n",
      "3     76.64\n",
      "4     96.62\n",
      "...     ...\n",
      "9563  91.00\n",
      "9564  66.78\n",
      "9565  36.48\n",
      "9566  62.39\n",
      "9567  67.87\n",
      "\n",
      "[9568 rows x 1 columns]\n",
      "[[1.00000000e+00 7.31700000e+01 5.35384890e+03 3.91741124e+05]\n",
      " [1.00000000e+00 5.90800000e+01 3.49044640e+03 2.06215573e+05]\n",
      " [1.00000000e+00 9.21400000e+01 8.48977960e+03 7.82248292e+05]\n",
      " ...\n",
      " [1.00000000e+00 3.64800000e+01 1.33079040e+03 4.85472338e+04]\n",
      " [1.00000000e+00 6.23900000e+01 3.89251210e+03 2.42853830e+05]\n",
      " [1.00000000e+00 6.78700000e+01 4.60633690e+03 3.12632085e+05]]\n",
      "        0      1          2              3\n",
      "0     1.0  73.17  5353.8489  391741.124013\n",
      "1     1.0  59.08  3490.4464  206215.573312\n",
      "2     1.0  92.14  8489.7796  782248.292344\n",
      "3     1.0  76.64  5873.6896  450159.570944\n",
      "4     1.0  96.62  9335.4244  901988.705528\n",
      "...   ...    ...        ...            ...\n",
      "9563  1.0  91.00  8281.0000  753571.000000\n",
      "9564  1.0  66.78  4459.5684  297809.977752\n",
      "9565  1.0  36.48  1330.7904   48547.233792\n",
      "9566  1.0  62.39  3892.5121  242853.829919\n",
      "9567  1.0  67.87  4606.3369  312632.085403\n",
      "\n",
      "[9568 rows x 4 columns]\n",
      "          1          2              3\n",
      "0     73.17  5353.8489  391741.124013\n",
      "1     59.08  3490.4464  206215.573312\n",
      "2     92.14  8489.7796  782248.292344\n",
      "3     76.64  5873.6896  450159.570944\n",
      "4     96.62  9335.4244  901988.705528\n",
      "...     ...        ...            ...\n",
      "9563  91.00  8281.0000  753571.000000\n",
      "9564  66.78  4459.5684  297809.977752\n",
      "9565  36.48  1330.7904   48547.233792\n",
      "9566  62.39  3892.5121  242853.829919\n",
      "9567  67.87  4606.3369  312632.085403\n",
      "\n",
      "[9568 rows x 3 columns]\n",
      "         RH        RH2            RH3\n",
      "0     73.17  5353.8489  391741.124013\n",
      "1     59.08  3490.4464  206215.573312\n",
      "2     92.14  8489.7796  782248.292344\n",
      "3     76.64  5873.6896  450159.570944\n",
      "4     96.62  9335.4244  901988.705528\n",
      "...     ...        ...            ...\n",
      "9563  91.00  8281.0000  753571.000000\n",
      "9564  66.78  4459.5684  297809.977752\n",
      "9565  36.48  1330.7904   48547.233792\n",
      "9566  62.39  3892.5121  242853.829919\n",
      "9567  67.87  4606.3369  312632.085403\n",
      "\n",
      "[9568 rows x 3 columns]\n",
      "The predicted vector y of output from this new model of RH is : \n",
      "       y_predicted\n",
      "0      454.369253\n",
      "1      447.069203\n",
      "2      462.940654\n",
      "3      456.188674\n",
      "4      464.154135\n",
      "...           ...\n",
      "9563   462.565038\n",
      "9564   450.967303\n",
      "9565   440.722089\n",
      "9566   448.694083\n",
      "9567   451.544615\n",
      "\n",
      "[9568 rows x 1 columns]\n",
      "The mean squared error (MSE) of y for RH under this new polynomial feature model is : \n",
      " 246.47407323169548\n",
      "The intercept term for RH is : \n",
      " 468.4135359711353\n",
      "The coefficients of RH, RH2, RH3, respectively in an array is : \n",
      " [-1.72921131e+00  3.21451721e-02 -1.52187969e-04]\n",
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                     PE   R-squared:                       0.154\n",
      "Model:                            OLS   Adj. R-squared:                  0.153\n",
      "Method:                 Least Squares   F-statistic:                     579.2\n",
      "Date:                Sun, 11 Oct 2020   Prob (F-statistic):               0.00\n",
      "Time:                        21:48:17   Log-Likelihood:                -39923.\n",
      "No. Observations:                9568   AIC:                         7.985e+04\n",
      "Df Residuals:                    9564   BIC:                         7.988e+04\n",
      "Df Model:                           3                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const        468.4135     10.545     44.422      0.000     447.744     489.083\n",
      "RH            -1.7292      0.486     -3.557      0.000      -2.682      -0.776\n",
      "RH2            0.0321      0.007      4.433      0.000       0.018       0.046\n",
      "RH3           -0.0002   3.51e-05     -4.340      0.000      -0.000   -8.34e-05\n",
      "==============================================================================\n",
      "Omnibus:                      707.867   Durbin-Watson:                   1.998\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              302.057\n",
      "Skew:                           0.223   Prob(JB):                     2.56e-66\n",
      "Kurtosis:                       2.253   Cond. No.                     3.26e+07\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The condition number is large, 3.26e+07. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n",
      "The reference value of t-statistic is : \n",
      " 1.9602120571430655\n",
      "The reference value of F-statistic (3,9564,0.05) is, from an online calculator : \n",
      " 2.6058\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nFinal Note\\n\\nAs such there wasn\\'t a drastic improvement in the model by adding the squared and cubed terms.\\nOnce they were added however, in most cases, they became statistically relevant to the model.\\n\\nThus we can surely say that the \"linear only\" model, without any higher terms of any of the \\npredictors may be preferred as addition of squared and cubed terms doesn\\'t improve significantly\\nthe prediction accuracy.\\n\\nAgain we cannot talk about test data, and implications from testing our models on the \\ntest data\\n\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Fri Sep 25 01:12:43 2020\n",
    "\n",
    "@author: DHRUV\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "HW2\n",
    "f\n",
    "\"\"\"\n",
    "\n",
    "\"\"\"\n",
    "FOR AT\n",
    "\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import statsmodels.api as sm\n",
    "from scipy.stats import t\n",
    "from statsmodels.tools.eval_measures import mse\n",
    "\n",
    "df = pd.read_csv('Power_Plant.csv')\n",
    "print(df)\n",
    "X_AT = df.drop(columns = ['V','AP','RH','PE'])\n",
    "y = df['PE']\n",
    "print(y)\n",
    "print(X_AT)\n",
    "poly = PolynomialFeatures(3)\n",
    "X_AT_modified=poly.fit_transform(X_AT)\n",
    "print(X_AT_modified)\n",
    "X_AT_new = pd.DataFrame(data = X_AT_modified)\n",
    "print(X_AT_new)\n",
    "X_AT_new = X_AT_new.iloc[:,1:4]\n",
    "print(X_AT_new)\n",
    "header_AT = ['AT','AT2','AT3']\n",
    "X_AT_new.columns = header_AT\n",
    "print(X_AT_new)\n",
    "reg_AT = LinearRegression()\n",
    "reg_AT.fit(X_AT_new, y)\n",
    "y_AT_predicted = reg_AT.predict(X_AT_new)\n",
    "print('The predicted vector y of output from this new model of AT is : \\n', pd.DataFrame(y_AT_predicted, columns = ['y_predicted']))\n",
    "print('The mean squared error (MSE) of y for AT under this new polynomial feature model is : \\n', mean_squared_error(y, y_AT_predicted))\n",
    "print('The intercept term for AT is : \\n', reg_AT.intercept_)\n",
    "print('The coefficients of AT, AT2, AT3, respectively in an array is : \\n', reg_AT.coef_)\n",
    "\"\"\"\n",
    "The mean squared error of y in only AT case was around 29, thus there does seem to be a slight imporvement\n",
    "in the error in y under a polynomial fit with degree of AT going to 3. \n",
    "\n",
    "However as a test data has not been analyzed for either cases, we can't say for sure how much\n",
    "of a truly tangible improvement this is for data that the trained model hasn't seen\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\"\"\"\n",
    "Analyzing relevance of each variable (AT,AT2,AT3) using t-test, using statsmodels library \n",
    "(using manual evaluation has been done before, and will just be code-elongating here)\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "X_AT_new_sm = sm.add_constant(X_AT_new)      \n",
    "est_AT = sm.OLS(y, X_AT_new_sm)\n",
    "est_data_AT = est_AT.fit()\n",
    "print(est_data_AT.summary())\n",
    "\n",
    "t_reference = t.ppf(1-0.025, 9564)\n",
    "print('The reference value of t-statistic is : \\n', t_reference)\n",
    "print('The reference value of F-statistic (3,9564,0.05) is, from an online calculator : \\n', 2.6058)\n",
    "\n",
    "\"\"\"\n",
    "As can be seen from both the t-test and the p-test, all the AT terms (AT,AT2,AT3)\n",
    "are relevant\n",
    "\n",
    "The F-observed is much larger than the F-reference (2.6058) and thus we can reject the \n",
    "hypothesis : \"All beta's are null\". Thus at least one of the predictor is relevant.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\"\"\"\n",
    "FOR V\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "X_V = df.drop(columns = ['AT','AP','RH','PE'])\n",
    "print(X_V)\n",
    "poly = PolynomialFeatures(3)\n",
    "X_V_modified=poly.fit_transform(X_V)\n",
    "print(X_V_modified)\n",
    "X_V_new = pd.DataFrame(data = X_V_modified)\n",
    "print(X_V_new)\n",
    "X_V_new = X_V_new.iloc[:,1:4]\n",
    "print(X_V_new)\n",
    "header_V = ['V','V2','V3']\n",
    "X_V_new.columns = header_V\n",
    "print(X_V_new)\n",
    "reg_V = LinearRegression()\n",
    "reg_V.fit(X_V_new, y)\n",
    "y_V_predicted = reg_V.predict(X_V_new)\n",
    "print('The predicted vector y of output from this new model of V is : \\n', pd.DataFrame(y_V_predicted, columns = ['y_predicted']))\n",
    "print('The mean squared error (MSE) of y for V under this new polynomial feature model is : \\n', mean_squared_error(y, y_V_predicted))\n",
    "print('The intercept term for V is : \\n', reg_V.intercept_)\n",
    "print('The coefficients of V, V2, V3, respectively in an array is : \\n', reg_V.coef_)\n",
    "\n",
    "\"\"\"\n",
    "The mean squared error of y in only V  case was around 70, thus there is an extremely minor \n",
    "improvement in the error in y under a polynomial fit with degree of V going to 3. \n",
    "\n",
    "Again neither model saw the test data, and thus performance under test data wasn't analyzed\n",
    "\n",
    "Again despite the addition of two more \"variables\" the improvement was very minor as compared to\n",
    "the only V case.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\"\"\"\n",
    "Analyzing relevance of each variable (V,V2,V3) using t-test, using statsmodels library \n",
    "(using manual evaluation has been done before, and will just be code-elongating here)\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "X_V_new_sm = sm.add_constant(X_V_new)      \n",
    "est_V = sm.OLS(y, X_V_new_sm)\n",
    "est_data_V = est_V.fit()\n",
    "print(est_data_V.summary())\n",
    "print('The reference value of t-statistic is : \\n', t_reference)\n",
    "print('The reference value of F-statistic (3,9564,0.05) is, from an online calculator : \\n', 2.6058)\n",
    "\n",
    "\"\"\"\n",
    "As can be seen from both the t-test and the p-test, For V\n",
    "\n",
    "V : relevant\n",
    "V2 : has p > 0.05 and also t-value not within appropriate bounds\n",
    "\n",
    "Thus V2 is surely irrelevant and the null hypothesis for V2 cannot be rejected. \n",
    "V2 is thus irrelevant\n",
    "\n",
    "V3 : has p < 0.05 (0.014 < 0.05)\n",
    "Thus V3 is statistically relevant, note that the V3 coefficient is extremely small,\n",
    "however with V3 cubed, the relevance of V3 as a possible variable can't be rejected.\n",
    "We can thus, for V3, reject the null hypothesis\n",
    "\n",
    "\n",
    "The F-observed is much larger than the F-reference (2.6058) and thus we can reject the \n",
    "hypothesis : \"All beta's are null\". Thus at least one of the predictor is relevant.\n",
    "\n",
    "So for V, V and V3 are legitimate predictors. V2 can be removed\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\"\"\"\n",
    "FOR AP\n",
    "\"\"\"\n",
    "\"\"\"\n",
    "NOTE : The results from sklearn and statsmodels in terms of co-efficients were different. This\n",
    "probably occured due to large values of AP2 and AP3. \n",
    "\n",
    "Here, despite difference in coefficients, both models predicted vector y with a similar accuracy.\n",
    "\n",
    "Thus while both models, despite the difference in their coefficients were correct, we used\n",
    "statsmodels due to its inbuilt functionality to calculate t-values. Thus the co-efficients using\n",
    "scikit/sklearn are different than the ones obtained using statsmodels here, however the predictions\n",
    "from both are similarly accurate. Thus both sklearn and statsmodels estimate coefficients differently\n",
    "when the values of predictors increase to a large value, however both are equally accurate in making\n",
    "the final prediction\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "X_AP = df.drop(columns = ['AT','V','RH','PE'])\n",
    "print(X_AP)\n",
    "poly = PolynomialFeatures(3)\n",
    "X_AP_modified=poly.fit_transform(X_AP)\n",
    "print(X_AP_modified)\n",
    "X_AP_new = pd.DataFrame(data = X_AP_modified)\n",
    "print(X_AP_new)\n",
    "X_AP_new = X_AP_new.iloc[:,1:4]\n",
    "print(X_AP_new)\n",
    "header_AP = ['AP','AP2','AP3']\n",
    "X_AP_new.columns = header_AP\n",
    "print(X_AP_new)\n",
    "X_AP_new_sm = sm.add_constant(X_AP_new)      \n",
    "est_AP = sm.OLS(y, X_AP_new_sm)\n",
    "est_data_AP = est_AP.fit()\n",
    "X_AP_new_sm_array = X_AP_new_sm.to_numpy()\n",
    "print(X_AP_new_sm_array)\n",
    "y_AP_predicted = est_data_AP.predict(X_AP_new_sm_array)\n",
    "print('The predicted vector y of output from this new model of AP is : \\n', pd.DataFrame(y_AP_predicted, columns = ['y_predicted']))\n",
    "print('The mean squared error (MSE) of y for AP under this new polynomial feature model is : \\n', mse(y,y_AP_predicted))\n",
    "print('The intercept term for AP, along with coefficients of AP, AP2, AP3, respectively in an array is : \\n', est_data_AP.params)\n",
    "\n",
    "\"\"\"\n",
    "The MSE for AP was 212 in the only AP case while here it is 211. Thus the improvement is negligible\n",
    "\n",
    "Thus the addition of AP2 and AP3 does little to increase the models accuracy\n",
    "\n",
    "Again no analysis done on test, unseen data\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\"\"\"\n",
    "Analyzing relevance of each variable (AP,AP2,AP3) using t-test, using statsmodels library \n",
    "(using manual evaluation has been done before, and will just be code-elongating here)\n",
    "\n",
    "\"\"\"\n",
    "print(est_data_AP.summary())\n",
    "print('The reference value of t-statistic is : \\n', t_reference)\n",
    "print('The reference value of F-statistic (3,9564,0.05) is, from an online calculator : \\n', 2.6058)\n",
    "\n",
    "\"\"\"\n",
    "As can be seen from both the t-test and the p-test, For AP\n",
    "\n",
    "For this model using AP, AP2, AP3\n",
    "\n",
    "We have\n",
    "\n",
    "p values for AP, AP2 and AP3 rather small implying that in this model, with the given coefficients\n",
    "all the three variables are relevant and the null hypothesis for each can be rejected.\n",
    "\n",
    "The F-statistic also says that total null hypothesis can be rejected making at least one of the \n",
    "predictors relevant in making the prediction.\n",
    "\n",
    "Again we will note that the MSE hasn't been significantly improved, thus despite the\n",
    "model relevance of AP2 and AP3, there is no real need to add them. Once they have been added\n",
    "however they do become significant in making the predictions.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\"\"\"\n",
    "FOR RH\n",
    "\"\"\"\n",
    "X_RH = df.drop(columns = ['AT','AP','V','PE'])\n",
    "print(X_RH)\n",
    "poly = PolynomialFeatures(3)\n",
    "X_RH_modified=poly.fit_transform(X_RH)\n",
    "print(X_RH_modified)\n",
    "X_RH_new = pd.DataFrame(data = X_RH_modified)\n",
    "print(X_RH_new)\n",
    "X_RH_new = X_RH_new.iloc[:,1:4]\n",
    "print(X_RH_new)\n",
    "header_RH = ['RH','RH2','RH3']\n",
    "X_RH_new.columns = header_RH\n",
    "print(X_RH_new)\n",
    "reg_RH = LinearRegression()\n",
    "reg_RH.fit(X_RH_new, y)\n",
    "y_RH_predicted = reg_RH.predict(X_RH_new)\n",
    "print('The predicted vector y of output from this new model of RH is : \\n', pd.DataFrame(y_RH_predicted, columns = ['y_predicted']))\n",
    "print('The mean squared error (MSE) of y for RH under this new polynomial feature model is : \\n', mean_squared_error(y, y_RH_predicted))\n",
    "print('The intercept term for RH is : \\n', reg_RH.intercept_)\n",
    "print('The coefficients of RH, RH2, RH3, respectively in an array is : \\n', reg_RH.coef_)\n",
    "\n",
    "\"\"\"\n",
    "The MSE for the only RH case was 246. Here also it is around 246. Next to no improvement\n",
    "in errors here. \n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\"\"\"\n",
    "Analyzing relevance of each variable (RH,RH2,RH3) using t-test, using statsmodels library \n",
    "(using manual evaluation has been done before, and will just be code-elongating here)\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "X_RH_new_sm = sm.add_constant(X_RH_new)      \n",
    "est_RH = sm.OLS(y, X_RH_new_sm)\n",
    "est_data_RH = est_RH.fit()\n",
    "print(est_data_RH.summary())\n",
    "print('The reference value of t-statistic is : \\n', t_reference)\n",
    "print('The reference value of F-statistic (3,9564,0.05) is, from an online calculator : \\n', 2.6058)\n",
    "\n",
    "\"\"\"\n",
    "As can be seen from both the t-test and the p-test\n",
    "\n",
    "RH, RH2 and RH3 are relevant and significant and thus can't be neglected. The null hypothesis\n",
    "for these variables can be rejected.\n",
    "\n",
    "Additionally the F-statistic says that we can reject the total null hypothesis, making at least\n",
    "one predictor of the three relevant\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Final Note\n",
    "\n",
    "As such there wasn't a drastic improvement in the model by adding the squared and cubed terms.\n",
    "Once they were added however, in most cases, they became statistically relevant to the model.\n",
    "\n",
    "Thus we can surely say that the \"linear only\" model, without any higher terms of any of the \n",
    "predictors may be preferred as addition of squared and cubed terms doesn't improve significantly\n",
    "the prediction accuracy.\n",
    "\n",
    "Again we cannot talk about test data, and implications from testing our models on the \n",
    "test data\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
