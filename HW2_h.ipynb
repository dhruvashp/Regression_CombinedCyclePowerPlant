{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         AT      V       AP     RH      PE\n",
      "0     14.96  41.76  1024.07  73.17  463.26\n",
      "1     25.18  62.96  1020.04  59.08  444.37\n",
      "2      5.11  39.40  1012.16  92.14  488.56\n",
      "3     20.86  57.32  1010.24  76.64  446.48\n",
      "4     10.82  37.50  1009.23  96.62  473.90\n",
      "...     ...    ...      ...    ...     ...\n",
      "9563  16.65  49.69  1014.01  91.00  460.03\n",
      "9564  13.19  39.18  1023.67  66.78  469.62\n",
      "9565  31.32  74.33  1012.92  36.48  429.57\n",
      "9566  24.48  69.45  1013.86  62.39  435.74\n",
      "9567  21.60  62.52  1017.23  67.87  453.28\n",
      "\n",
      "[9568 rows x 5 columns]\n",
      "0       463.26\n",
      "1       444.37\n",
      "2       488.56\n",
      "3       446.48\n",
      "4       473.90\n",
      "         ...  \n",
      "9563    460.03\n",
      "9564    469.62\n",
      "9565    429.57\n",
      "9566    435.74\n",
      "9567    453.28\n",
      "Name: PE, Length: 9568, dtype: float64\n",
      "         AT      V       AP     RH\n",
      "0     14.96  41.76  1024.07  73.17\n",
      "1     25.18  62.96  1020.04  59.08\n",
      "2      5.11  39.40  1012.16  92.14\n",
      "3     20.86  57.32  1010.24  76.64\n",
      "4     10.82  37.50  1009.23  96.62\n",
      "...     ...    ...      ...    ...\n",
      "9563  16.65  49.69  1014.01  91.00\n",
      "9564  13.19  39.18  1023.67  66.78\n",
      "9565  31.32  74.33  1012.92  36.48\n",
      "9566  24.48  69.45  1013.86  62.39\n",
      "9567  21.60  62.52  1017.23  67.87\n",
      "\n",
      "[9568 rows x 4 columns]\n",
      "        0      1      2        3      4         5          6           7  \\\n",
      "0     1.0  14.96  41.76  1024.07  73.17  223.8016   624.7296  15320.0872   \n",
      "1     1.0  25.18  62.96  1020.04  59.08  634.0324  1585.3328  25684.6072   \n",
      "2     1.0   5.11  39.40  1012.16  92.14   26.1121   201.3340   5172.1376   \n",
      "3     1.0  20.86  57.32  1010.24  76.64  435.1396  1195.6952  21073.6064   \n",
      "4     1.0  10.82  37.50  1009.23  96.62  117.0724   405.7500  10919.8686   \n",
      "...   ...    ...    ...      ...    ...       ...        ...         ...   \n",
      "9563  1.0  16.65  49.69  1014.01  91.00  277.2225   827.3385  16883.2665   \n",
      "9564  1.0  13.19  39.18  1023.67  66.78  173.9761   516.7842  13502.2073   \n",
      "9565  1.0  31.32  74.33  1012.92  36.48  980.9424  2328.0156  31724.6544   \n",
      "9566  1.0  24.48  69.45  1013.86  62.39  599.2704  1700.1360  24819.2928   \n",
      "9567  1.0  21.60  62.52  1017.23  67.87  466.5600  1350.4320  21972.1680   \n",
      "\n",
      "              8          9          10         11            12          13  \\\n",
      "0     1094.6232  1743.8976  42765.1632  3055.5792  1.048719e+06  74931.2019   \n",
      "1     1487.6344  3963.9616  64221.7184  3719.6768  1.040482e+06  60263.9632   \n",
      "2      470.8354  1552.3600  39879.1040  3630.3160  1.024468e+06  93260.4224   \n",
      "3     1598.7104  3285.5824  57906.9568  4393.0048  1.020585e+06  77424.7936   \n",
      "4     1045.4284  1406.2500  37846.1250  3623.2500  1.018545e+06  97511.8026   \n",
      "...         ...        ...         ...        ...           ...         ...   \n",
      "9563  1515.1500  2469.0961  50386.1569  4521.7900  1.028216e+06  92274.9100   \n",
      "9564   880.8282  1535.0724  40107.3906  2616.4404  1.047900e+06  68360.6826   \n",
      "9565  1142.5536  5524.9489  75290.3436  2711.5584  1.026007e+06  36951.3216   \n",
      "9566  1527.3072  4823.3025  70412.5770  4332.9855  1.027912e+06  63254.7254   \n",
      "9567  1465.9920  3908.7504  63597.2196  4243.2324  1.034757e+06  69039.4001   \n",
      "\n",
      "             14  \n",
      "0     5353.8489  \n",
      "1     3490.4464  \n",
      "2     8489.7796  \n",
      "3     5873.6896  \n",
      "4     9335.4244  \n",
      "...         ...  \n",
      "9563  8281.0000  \n",
      "9564  4459.5684  \n",
      "9565  1330.7904  \n",
      "9566  3892.5121  \n",
      "9567  4606.3369  \n",
      "\n",
      "[9568 rows x 15 columns]\n",
      "         1      2        3      4         5          6           7   \\\n",
      "0     14.96  41.76  1024.07  73.17  223.8016   624.7296  15320.0872   \n",
      "1     25.18  62.96  1020.04  59.08  634.0324  1585.3328  25684.6072   \n",
      "2      5.11  39.40  1012.16  92.14   26.1121   201.3340   5172.1376   \n",
      "3     20.86  57.32  1010.24  76.64  435.1396  1195.6952  21073.6064   \n",
      "4     10.82  37.50  1009.23  96.62  117.0724   405.7500  10919.8686   \n",
      "...     ...    ...      ...    ...       ...        ...         ...   \n",
      "9563  16.65  49.69  1014.01  91.00  277.2225   827.3385  16883.2665   \n",
      "9564  13.19  39.18  1023.67  66.78  173.9761   516.7842  13502.2073   \n",
      "9565  31.32  74.33  1012.92  36.48  980.9424  2328.0156  31724.6544   \n",
      "9566  24.48  69.45  1013.86  62.39  599.2704  1700.1360  24819.2928   \n",
      "9567  21.60  62.52  1017.23  67.87  466.5600  1350.4320  21972.1680   \n",
      "\n",
      "             8          9           10         11            12          13  \\\n",
      "0     1094.6232  1743.8976  42765.1632  3055.5792  1.048719e+06  74931.2019   \n",
      "1     1487.6344  3963.9616  64221.7184  3719.6768  1.040482e+06  60263.9632   \n",
      "2      470.8354  1552.3600  39879.1040  3630.3160  1.024468e+06  93260.4224   \n",
      "3     1598.7104  3285.5824  57906.9568  4393.0048  1.020585e+06  77424.7936   \n",
      "4     1045.4284  1406.2500  37846.1250  3623.2500  1.018545e+06  97511.8026   \n",
      "...         ...        ...         ...        ...           ...         ...   \n",
      "9563  1515.1500  2469.0961  50386.1569  4521.7900  1.028216e+06  92274.9100   \n",
      "9564   880.8282  1535.0724  40107.3906  2616.4404  1.047900e+06  68360.6826   \n",
      "9565  1142.5536  5524.9489  75290.3436  2711.5584  1.026007e+06  36951.3216   \n",
      "9566  1527.3072  4823.3025  70412.5770  4332.9855  1.027912e+06  63254.7254   \n",
      "9567  1465.9920  3908.7504  63597.2196  4243.2324  1.034757e+06  69039.4001   \n",
      "\n",
      "             14  \n",
      "0     5353.8489  \n",
      "1     3490.4464  \n",
      "2     8489.7796  \n",
      "3     5873.6896  \n",
      "4     9335.4244  \n",
      "...         ...  \n",
      "9563  8281.0000  \n",
      "9564  4459.5684  \n",
      "9565  1330.7904  \n",
      "9566  3892.5121  \n",
      "9567  4606.3369  \n",
      "\n",
      "[9568 rows x 14 columns]\n",
      "         AT      V       AP     RH       AT2       AT*V       AT*AP  \\\n",
      "0     14.96  41.76  1024.07  73.17  223.8016   624.7296  15320.0872   \n",
      "1     25.18  62.96  1020.04  59.08  634.0324  1585.3328  25684.6072   \n",
      "2      5.11  39.40  1012.16  92.14   26.1121   201.3340   5172.1376   \n",
      "3     20.86  57.32  1010.24  76.64  435.1396  1195.6952  21073.6064   \n",
      "4     10.82  37.50  1009.23  96.62  117.0724   405.7500  10919.8686   \n",
      "...     ...    ...      ...    ...       ...        ...         ...   \n",
      "9563  16.65  49.69  1014.01  91.00  277.2225   827.3385  16883.2665   \n",
      "9564  13.19  39.18  1023.67  66.78  173.9761   516.7842  13502.2073   \n",
      "9565  31.32  74.33  1012.92  36.48  980.9424  2328.0156  31724.6544   \n",
      "9566  24.48  69.45  1013.86  62.39  599.2704  1700.1360  24819.2928   \n",
      "9567  21.60  62.52  1017.23  67.87  466.5600  1350.4320  21972.1680   \n",
      "\n",
      "          AT*RH         V2        V*AP       V*RH           AP2       AP*RH  \\\n",
      "0     1094.6232  1743.8976  42765.1632  3055.5792  1.048719e+06  74931.2019   \n",
      "1     1487.6344  3963.9616  64221.7184  3719.6768  1.040482e+06  60263.9632   \n",
      "2      470.8354  1552.3600  39879.1040  3630.3160  1.024468e+06  93260.4224   \n",
      "3     1598.7104  3285.5824  57906.9568  4393.0048  1.020585e+06  77424.7936   \n",
      "4     1045.4284  1406.2500  37846.1250  3623.2500  1.018545e+06  97511.8026   \n",
      "...         ...        ...         ...        ...           ...         ...   \n",
      "9563  1515.1500  2469.0961  50386.1569  4521.7900  1.028216e+06  92274.9100   \n",
      "9564   880.8282  1535.0724  40107.3906  2616.4404  1.047900e+06  68360.6826   \n",
      "9565  1142.5536  5524.9489  75290.3436  2711.5584  1.026007e+06  36951.3216   \n",
      "9566  1527.3072  4823.3025  70412.5770  4332.9855  1.027912e+06  63254.7254   \n",
      "9567  1465.9920  3908.7504  63597.2196  4243.2324  1.034757e+06  69039.4001   \n",
      "\n",
      "            RH2  \n",
      "0     5353.8489  \n",
      "1     3490.4464  \n",
      "2     8489.7796  \n",
      "3     5873.6896  \n",
      "4     9335.4244  \n",
      "...         ...  \n",
      "9563  8281.0000  \n",
      "9564  4459.5684  \n",
      "9565  1330.7904  \n",
      "9566  3892.5121  \n",
      "9567  4606.3369  \n",
      "\n",
      "[9568 rows x 14 columns]\n",
      "         AT      V       AP     RH       AT2       AT*V       AT*AP  \\\n",
      "0     14.96  41.76  1024.07  73.17  223.8016   624.7296  15320.0872   \n",
      "1     25.18  62.96  1020.04  59.08  634.0324  1585.3328  25684.6072   \n",
      "2      5.11  39.40  1012.16  92.14   26.1121   201.3340   5172.1376   \n",
      "3     20.86  57.32  1010.24  76.64  435.1396  1195.6952  21073.6064   \n",
      "4     10.82  37.50  1009.23  96.62  117.0724   405.7500  10919.8686   \n",
      "...     ...    ...      ...    ...       ...        ...         ...   \n",
      "9563  16.65  49.69  1014.01  91.00  277.2225   827.3385  16883.2665   \n",
      "9564  13.19  39.18  1023.67  66.78  173.9761   516.7842  13502.2073   \n",
      "9565  31.32  74.33  1012.92  36.48  980.9424  2328.0156  31724.6544   \n",
      "9566  24.48  69.45  1013.86  62.39  599.2704  1700.1360  24819.2928   \n",
      "9567  21.60  62.52  1017.23  67.87  466.5600  1350.4320  21972.1680   \n",
      "\n",
      "          AT*RH         V2        V*AP       V*RH           AP2       AP*RH  \\\n",
      "0     1094.6232  1743.8976  42765.1632  3055.5792  1.048719e+06  74931.2019   \n",
      "1     1487.6344  3963.9616  64221.7184  3719.6768  1.040482e+06  60263.9632   \n",
      "2      470.8354  1552.3600  39879.1040  3630.3160  1.024468e+06  93260.4224   \n",
      "3     1598.7104  3285.5824  57906.9568  4393.0048  1.020585e+06  77424.7936   \n",
      "4     1045.4284  1406.2500  37846.1250  3623.2500  1.018545e+06  97511.8026   \n",
      "...         ...        ...         ...        ...           ...         ...   \n",
      "9563  1515.1500  2469.0961  50386.1569  4521.7900  1.028216e+06  92274.9100   \n",
      "9564   880.8282  1535.0724  40107.3906  2616.4404  1.047900e+06  68360.6826   \n",
      "9565  1142.5536  5524.9489  75290.3436  2711.5584  1.026007e+06  36951.3216   \n",
      "9566  1527.3072  4823.3025  70412.5770  4332.9855  1.027912e+06  63254.7254   \n",
      "9567  1465.9920  3908.7504  63597.2196  4243.2324  1.034757e+06  69039.4001   \n",
      "\n",
      "            RH2      PE  \n",
      "0     5353.8489  463.26  \n",
      "1     3490.4464  444.37  \n",
      "2     8489.7796  488.56  \n",
      "3     5873.6896  446.48  \n",
      "4     9335.4244  473.90  \n",
      "...         ...     ...  \n",
      "9563  8281.0000  460.03  \n",
      "9564  4459.5684  469.62  \n",
      "9565  1330.7904  429.57  \n",
      "9566  3892.5121  435.74  \n",
      "9567  4606.3369  453.28  \n",
      "\n",
      "[9568 rows x 15 columns]\n",
      "         AT      V       AP     RH       AT2       AT*V       AT*AP  \\\n",
      "4033  10.48  36.71  1023.18  81.37  109.8304   384.7208  10722.9264   \n",
      "2318  22.36  58.79  1011.77  87.51  499.9696  1314.5444  22623.1772   \n",
      "6158  12.93  36.71  1013.22  83.44  167.1849   474.6603  13100.9346   \n",
      "5952  21.50  44.58  1016.87  57.58  462.2500   958.4700  21862.7050   \n",
      "538   14.30  54.30  1015.16  75.29  204.4900   776.4900  14516.7880   \n",
      "...     ...    ...      ...    ...       ...        ...         ...   \n",
      "56    27.31  64.44  1014.65  57.27  745.8361  1759.8564  27710.0915   \n",
      "3919   5.68  40.35  1012.11  92.86   32.2624   229.1880   5748.7848   \n",
      "6636  26.54  69.48  1010.70  66.09  704.3716  1843.9992  26823.9780   \n",
      "9508  10.63  42.28  1008.37  92.68  112.9969   449.4364  10718.9731   \n",
      "6610  28.82  71.80  1010.97  67.64  830.5924  2069.2760  29136.1554   \n",
      "\n",
      "          AT*RH         V2        V*AP       V*RH           AP2       AP*RH  \\\n",
      "4033   852.7576  1347.6241  37560.9378  2987.0927  1.046897e+06  83256.1566   \n",
      "2318  1956.7236  3456.2641  59481.9583  5144.7129  1.023679e+06  88539.9927   \n",
      "6158  1078.8792  1347.6241  37195.3062  3063.0824  1.026615e+06  84543.0768   \n",
      "5952  1237.9700  1987.3764  45332.0646  2566.9164  1.034025e+06  58551.3746   \n",
      "538   1076.6470  2948.4900  55123.1880  4088.2470  1.030550e+06  76431.3964   \n",
      "...         ...        ...         ...        ...           ...         ...   \n",
      "56    1564.0437  4152.5136  65384.0460  3690.4788  1.029515e+06  58109.0055   \n",
      "3919   527.4448  1628.1225  40838.6385  3746.9010  1.024367e+06  93984.5346   \n",
      "6636  1754.0286  4827.4704  70223.4360  4591.9332  1.021514e+06  66797.1630   \n",
      "9508   985.1884  1787.5984  42633.8836  3918.5104  1.016810e+06  93455.7316   \n",
      "6610  1949.3848  5155.2400  72587.6460  4856.5520  1.022060e+06  68382.0108   \n",
      "\n",
      "            RH2      PE  \n",
      "4033  6621.0769  473.30  \n",
      "2318  7658.0001  446.49  \n",
      "6158  6962.2336  472.42  \n",
      "5952  3315.4564  460.20  \n",
      "538   5668.5841  464.90  \n",
      "...         ...     ...  \n",
      "56    3279.8529  442.77  \n",
      "3919  8622.9796  486.79  \n",
      "6636  4367.8881  432.56  \n",
      "9508  8589.5824  474.97  \n",
      "6610  4575.1696  436.71  \n",
      "\n",
      "[6697 rows x 15 columns]\n",
      "         AT      V       AP     RH       AT2       AT*V       AT*AP  \\\n",
      "2902  30.29  74.16  1008.77  75.23  917.4841  2246.3064  30555.6433   \n",
      "5903  22.76  49.21  1014.35  48.85  518.0176  1120.0196  23086.6060   \n",
      "3502   7.87  41.17  1020.33  77.77   61.9369   324.0079   8029.9971   \n",
      "6130  27.71  72.99  1007.18  72.68  767.8441  2022.5529  27908.9578   \n",
      "7260  13.56  42.34  1017.95  93.83  183.8736   574.1304  13803.4020   \n",
      "...     ...    ...      ...    ...       ...        ...         ...   \n",
      "1396  18.34  44.63  1000.76  89.27  336.3556   818.5142  18353.9384   \n",
      "824   13.49  44.63  1019.12  70.02  181.9801   602.0587  13747.9288   \n",
      "1438  15.61  38.52  1018.40  80.99  243.6721   601.2972  15897.2240   \n",
      "7938  27.83  69.04  1009.69  63.79  774.5089  1921.3832  28099.6727   \n",
      "8947  15.55  45.09  1014.33  62.19  241.8025   701.1495  15772.8315   \n",
      "\n",
      "          AT*RH         V2        V*AP       V*RH           AP2       AP*RH  \\\n",
      "2902  2278.7167  5499.7056  74810.3832  5579.0568  1.017617e+06  75889.7671   \n",
      "5903  1111.8260  2421.6241  49916.1635  2403.9085  1.028906e+06  49550.9975   \n",
      "3502   612.0499  1694.9689  42006.9861  3201.7909  1.041073e+06  79351.0641   \n",
      "6130  2013.9628  5327.5401  73514.0682  5304.9132  1.014412e+06  73201.8424   \n",
      "7260  1272.3348  1792.6756  43100.0030  3972.7622  1.036222e+06  95514.2485   \n",
      "...         ...        ...         ...        ...           ...         ...   \n",
      "1396  1637.2118  1991.8369  44663.9188  3984.1201  1.001521e+06  89337.8452   \n",
      "824    944.5698  1991.8369  45483.3256  3124.9926  1.038606e+06  71358.7824   \n",
      "1438  1264.2539  1483.7904  39228.7680  3119.7348  1.037139e+06  82480.2160   \n",
      "7938  1775.2757  4766.5216  69708.9976  4404.0616  1.019474e+06  64408.1251   \n",
      "8947   967.0545  2033.1081  45736.1397  2804.1471  1.028865e+06  63081.1827   \n",
      "\n",
      "            RH2      PE  \n",
      "2902  5659.5529  431.39  \n",
      "5903  2386.3225  448.73  \n",
      "3502  6048.1729  486.20  \n",
      "6130  5282.3824  433.01  \n",
      "7260  8804.0689  462.60  \n",
      "...         ...     ...  \n",
      "1396  7969.1329  455.22  \n",
      "824   4902.8004  471.08  \n",
      "1438  6559.3801  439.21  \n",
      "7938  4069.1641  443.24  \n",
      "8947  3867.5961  457.36  \n",
      "\n",
      "[2871 rows x 15 columns]\n",
      "         AT      V       AP     RH       AT2       AT*V       AT*AP  \\\n",
      "0     10.48  36.71  1023.18  81.37  109.8304   384.7208  10722.9264   \n",
      "1     22.36  58.79  1011.77  87.51  499.9696  1314.5444  22623.1772   \n",
      "2     12.93  36.71  1013.22  83.44  167.1849   474.6603  13100.9346   \n",
      "3     21.50  44.58  1016.87  57.58  462.2500   958.4700  21862.7050   \n",
      "4     14.30  54.30  1015.16  75.29  204.4900   776.4900  14516.7880   \n",
      "...     ...    ...      ...    ...       ...        ...         ...   \n",
      "6692  27.31  64.44  1014.65  57.27  745.8361  1759.8564  27710.0915   \n",
      "6693   5.68  40.35  1012.11  92.86   32.2624   229.1880   5748.7848   \n",
      "6694  26.54  69.48  1010.70  66.09  704.3716  1843.9992  26823.9780   \n",
      "6695  10.63  42.28  1008.37  92.68  112.9969   449.4364  10718.9731   \n",
      "6696  28.82  71.80  1010.97  67.64  830.5924  2069.2760  29136.1554   \n",
      "\n",
      "          AT*RH         V2        V*AP       V*RH           AP2       AP*RH  \\\n",
      "0      852.7576  1347.6241  37560.9378  2987.0927  1.046897e+06  83256.1566   \n",
      "1     1956.7236  3456.2641  59481.9583  5144.7129  1.023679e+06  88539.9927   \n",
      "2     1078.8792  1347.6241  37195.3062  3063.0824  1.026615e+06  84543.0768   \n",
      "3     1237.9700  1987.3764  45332.0646  2566.9164  1.034025e+06  58551.3746   \n",
      "4     1076.6470  2948.4900  55123.1880  4088.2470  1.030550e+06  76431.3964   \n",
      "...         ...        ...         ...        ...           ...         ...   \n",
      "6692  1564.0437  4152.5136  65384.0460  3690.4788  1.029515e+06  58109.0055   \n",
      "6693   527.4448  1628.1225  40838.6385  3746.9010  1.024367e+06  93984.5346   \n",
      "6694  1754.0286  4827.4704  70223.4360  4591.9332  1.021514e+06  66797.1630   \n",
      "6695   985.1884  1787.5984  42633.8836  3918.5104  1.016810e+06  93455.7316   \n",
      "6696  1949.3848  5155.2400  72587.6460  4856.5520  1.022060e+06  68382.0108   \n",
      "\n",
      "            RH2      PE  \n",
      "0     6621.0769  473.30  \n",
      "1     7658.0001  446.49  \n",
      "2     6962.2336  472.42  \n",
      "3     3315.4564  460.20  \n",
      "4     5668.5841  464.90  \n",
      "...         ...     ...  \n",
      "6692  3279.8529  442.77  \n",
      "6693  8622.9796  486.79  \n",
      "6694  4367.8881  432.56  \n",
      "6695  8589.5824  474.97  \n",
      "6696  4575.1696  436.71  \n",
      "\n",
      "[6697 rows x 15 columns]\n",
      "         AT      V       AP     RH       AT2       AT*V       AT*AP  \\\n",
      "0     30.29  74.16  1008.77  75.23  917.4841  2246.3064  30555.6433   \n",
      "1     22.76  49.21  1014.35  48.85  518.0176  1120.0196  23086.6060   \n",
      "2      7.87  41.17  1020.33  77.77   61.9369   324.0079   8029.9971   \n",
      "3     27.71  72.99  1007.18  72.68  767.8441  2022.5529  27908.9578   \n",
      "4     13.56  42.34  1017.95  93.83  183.8736   574.1304  13803.4020   \n",
      "...     ...    ...      ...    ...       ...        ...         ...   \n",
      "2866  18.34  44.63  1000.76  89.27  336.3556   818.5142  18353.9384   \n",
      "2867  13.49  44.63  1019.12  70.02  181.9801   602.0587  13747.9288   \n",
      "2868  15.61  38.52  1018.40  80.99  243.6721   601.2972  15897.2240   \n",
      "2869  27.83  69.04  1009.69  63.79  774.5089  1921.3832  28099.6727   \n",
      "2870  15.55  45.09  1014.33  62.19  241.8025   701.1495  15772.8315   \n",
      "\n",
      "          AT*RH         V2        V*AP       V*RH           AP2       AP*RH  \\\n",
      "0     2278.7167  5499.7056  74810.3832  5579.0568  1.017617e+06  75889.7671   \n",
      "1     1111.8260  2421.6241  49916.1635  2403.9085  1.028906e+06  49550.9975   \n",
      "2      612.0499  1694.9689  42006.9861  3201.7909  1.041073e+06  79351.0641   \n",
      "3     2013.9628  5327.5401  73514.0682  5304.9132  1.014412e+06  73201.8424   \n",
      "4     1272.3348  1792.6756  43100.0030  3972.7622  1.036222e+06  95514.2485   \n",
      "...         ...        ...         ...        ...           ...         ...   \n",
      "2866  1637.2118  1991.8369  44663.9188  3984.1201  1.001521e+06  89337.8452   \n",
      "2867   944.5698  1991.8369  45483.3256  3124.9926  1.038606e+06  71358.7824   \n",
      "2868  1264.2539  1483.7904  39228.7680  3119.7348  1.037139e+06  82480.2160   \n",
      "2869  1775.2757  4766.5216  69708.9976  4404.0616  1.019474e+06  64408.1251   \n",
      "2870   967.0545  2033.1081  45736.1397  2804.1471  1.028865e+06  63081.1827   \n",
      "\n",
      "            RH2      PE  \n",
      "0     5659.5529  431.39  \n",
      "1     2386.3225  448.73  \n",
      "2     6048.1729  486.20  \n",
      "3     5282.3824  433.01  \n",
      "4     8804.0689  462.60  \n",
      "...         ...     ...  \n",
      "2866  7969.1329  455.22  \n",
      "2867  4902.8004  471.08  \n",
      "2868  6559.3801  439.21  \n",
      "2869  4069.1641  443.24  \n",
      "2870  3867.5961  457.36  \n",
      "\n",
      "[2871 rows x 15 columns]\n",
      "The randomly selected 70% training features dataset is : \n",
      "          AT      V       AP     RH       AT2       AT*V       AT*AP  \\\n",
      "0     10.48  36.71  1023.18  81.37  109.8304   384.7208  10722.9264   \n",
      "1     22.36  58.79  1011.77  87.51  499.9696  1314.5444  22623.1772   \n",
      "2     12.93  36.71  1013.22  83.44  167.1849   474.6603  13100.9346   \n",
      "3     21.50  44.58  1016.87  57.58  462.2500   958.4700  21862.7050   \n",
      "4     14.30  54.30  1015.16  75.29  204.4900   776.4900  14516.7880   \n",
      "...     ...    ...      ...    ...       ...        ...         ...   \n",
      "6692  27.31  64.44  1014.65  57.27  745.8361  1759.8564  27710.0915   \n",
      "6693   5.68  40.35  1012.11  92.86   32.2624   229.1880   5748.7848   \n",
      "6694  26.54  69.48  1010.70  66.09  704.3716  1843.9992  26823.9780   \n",
      "6695  10.63  42.28  1008.37  92.68  112.9969   449.4364  10718.9731   \n",
      "6696  28.82  71.80  1010.97  67.64  830.5924  2069.2760  29136.1554   \n",
      "\n",
      "          AT*RH         V2        V*AP       V*RH           AP2       AP*RH  \\\n",
      "0      852.7576  1347.6241  37560.9378  2987.0927  1.046897e+06  83256.1566   \n",
      "1     1956.7236  3456.2641  59481.9583  5144.7129  1.023679e+06  88539.9927   \n",
      "2     1078.8792  1347.6241  37195.3062  3063.0824  1.026615e+06  84543.0768   \n",
      "3     1237.9700  1987.3764  45332.0646  2566.9164  1.034025e+06  58551.3746   \n",
      "4     1076.6470  2948.4900  55123.1880  4088.2470  1.030550e+06  76431.3964   \n",
      "...         ...        ...         ...        ...           ...         ...   \n",
      "6692  1564.0437  4152.5136  65384.0460  3690.4788  1.029515e+06  58109.0055   \n",
      "6693   527.4448  1628.1225  40838.6385  3746.9010  1.024367e+06  93984.5346   \n",
      "6694  1754.0286  4827.4704  70223.4360  4591.9332  1.021514e+06  66797.1630   \n",
      "6695   985.1884  1787.5984  42633.8836  3918.5104  1.016810e+06  93455.7316   \n",
      "6696  1949.3848  5155.2400  72587.6460  4856.5520  1.022060e+06  68382.0108   \n",
      "\n",
      "            RH2  \n",
      "0     6621.0769  \n",
      "1     7658.0001  \n",
      "2     6962.2336  \n",
      "3     3315.4564  \n",
      "4     5668.5841  \n",
      "...         ...  \n",
      "6692  3279.8529  \n",
      "6693  8622.9796  \n",
      "6694  4367.8881  \n",
      "6695  8589.5824  \n",
      "6696  4575.1696  \n",
      "\n",
      "[6697 rows x 14 columns]\n",
      "The randomly selected 30% test feature dataset is : \n",
      "          AT      V       AP     RH       AT2       AT*V       AT*AP  \\\n",
      "0     30.29  74.16  1008.77  75.23  917.4841  2246.3064  30555.6433   \n",
      "1     22.76  49.21  1014.35  48.85  518.0176  1120.0196  23086.6060   \n",
      "2      7.87  41.17  1020.33  77.77   61.9369   324.0079   8029.9971   \n",
      "3     27.71  72.99  1007.18  72.68  767.8441  2022.5529  27908.9578   \n",
      "4     13.56  42.34  1017.95  93.83  183.8736   574.1304  13803.4020   \n",
      "...     ...    ...      ...    ...       ...        ...         ...   \n",
      "2866  18.34  44.63  1000.76  89.27  336.3556   818.5142  18353.9384   \n",
      "2867  13.49  44.63  1019.12  70.02  181.9801   602.0587  13747.9288   \n",
      "2868  15.61  38.52  1018.40  80.99  243.6721   601.2972  15897.2240   \n",
      "2869  27.83  69.04  1009.69  63.79  774.5089  1921.3832  28099.6727   \n",
      "2870  15.55  45.09  1014.33  62.19  241.8025   701.1495  15772.8315   \n",
      "\n",
      "          AT*RH         V2        V*AP       V*RH           AP2       AP*RH  \\\n",
      "0     2278.7167  5499.7056  74810.3832  5579.0568  1.017617e+06  75889.7671   \n",
      "1     1111.8260  2421.6241  49916.1635  2403.9085  1.028906e+06  49550.9975   \n",
      "2      612.0499  1694.9689  42006.9861  3201.7909  1.041073e+06  79351.0641   \n",
      "3     2013.9628  5327.5401  73514.0682  5304.9132  1.014412e+06  73201.8424   \n",
      "4     1272.3348  1792.6756  43100.0030  3972.7622  1.036222e+06  95514.2485   \n",
      "...         ...        ...         ...        ...           ...         ...   \n",
      "2866  1637.2118  1991.8369  44663.9188  3984.1201  1.001521e+06  89337.8452   \n",
      "2867   944.5698  1991.8369  45483.3256  3124.9926  1.038606e+06  71358.7824   \n",
      "2868  1264.2539  1483.7904  39228.7680  3119.7348  1.037139e+06  82480.2160   \n",
      "2869  1775.2757  4766.5216  69708.9976  4404.0616  1.019474e+06  64408.1251   \n",
      "2870   967.0545  2033.1081  45736.1397  2804.1471  1.028865e+06  63081.1827   \n",
      "\n",
      "            RH2  \n",
      "0     5659.5529  \n",
      "1     2386.3225  \n",
      "2     6048.1729  \n",
      "3     5282.3824  \n",
      "4     8804.0689  \n",
      "...         ...  \n",
      "2866  7969.1329  \n",
      "2867  4902.8004  \n",
      "2868  6559.3801  \n",
      "2869  4069.1641  \n",
      "2870  3867.5961  \n",
      "\n",
      "[2871 rows x 14 columns]\n",
      "The randomly selected (training feature corresponding) 70% training output is : \n",
      " 0       473.30\n",
      "1       446.49\n",
      "2       472.42\n",
      "3       460.20\n",
      "4       464.90\n",
      "         ...  \n",
      "6692    442.77\n",
      "6693    486.79\n",
      "6694    432.56\n",
      "6695    474.97\n",
      "6696    436.71\n",
      "Name: PE, Length: 6697, dtype: float64\n",
      "The randomly selected (test feature corresponding) 30% test output is : \n",
      " 0       431.39\n",
      "1       448.73\n",
      "2       486.20\n",
      "3       433.01\n",
      "4       462.60\n",
      "         ...  \n",
      "2866    455.22\n",
      "2867    471.08\n",
      "2868    439.21\n",
      "2869    443.24\n",
      "2870    457.36\n",
      "Name: PE, Length: 2871, dtype: float64\n",
      "The y_train_predicted is : \n",
      "       y_train_predicted\n",
      "0            476.614705\n",
      "1            444.781400\n",
      "2            471.360157\n",
      "3            454.751003\n",
      "4            463.348964\n",
      "...                 ...\n",
      "6692         440.690483\n",
      "6693         486.203525\n",
      "6694         438.529739\n",
      "6695         473.282938\n",
      "6696         434.798680\n",
      "\n",
      "[6697 rows x 1 columns]\n",
      "The y_test_predicted is : \n",
      "       y_test_predicted\n",
      "0           430.585433\n",
      "1           451.743100\n",
      "2           481.847079\n",
      "3           434.167101\n",
      "4           466.239668\n",
      "...                ...\n",
      "2866        454.753717\n",
      "2867        469.015302\n",
      "2868        465.047835\n",
      "2869        436.916294\n",
      "2870        465.041634\n",
      "\n",
      "[2871 rows x 1 columns]\n",
      "The MSE_train is : \n",
      " 18.03052394585632\n",
      "The MSE_test is : \n",
      " 18.29660770661391\n",
      "The intercept obtained for this model is : \n",
      " -8060.6849024425455\n",
      "The coefficients obtained for the predictors in an array in their respective order is : \n",
      " [-2.46801002e+00 -4.70385255e+00  1.67076062e+01  4.61006398e+00\n",
      "  1.42519087e-02  1.24913629e-02 -6.06433099e-05 -6.94299161e-03\n",
      " -1.12678666e-03  4.18660041e-03  5.32691170e-04 -8.14044445e-03\n",
      " -4.27214904e-03 -2.02381775e-03]\n",
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                     PE   R-squared:                       0.939\n",
      "Model:                            OLS   Adj. R-squared:                  0.938\n",
      "Method:                 Least Squares   F-statistic:                     7297.\n",
      "Date:                Sun, 11 Oct 2020   Prob (F-statistic):               0.00\n",
      "Time:                        21:46:44   Log-Likelihood:                -19187.\n",
      "No. Observations:                6697   AIC:                         3.840e+04\n",
      "Df Residuals:                    6682   BIC:                         3.851e+04\n",
      "Df Model:                          14                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const      -8060.6849   1454.636     -5.541      0.000   -1.09e+04   -5209.134\n",
      "AT            -2.4680      3.721     -0.663      0.507      -9.762       4.826\n",
      "V             -4.7039      1.791     -2.626      0.009      -8.216      -1.192\n",
      "AP            16.7076      2.824      5.917      0.000      11.172      22.243\n",
      "RH             4.6101      1.027      4.487      0.000       2.596       6.624\n",
      "AT2            0.0143      0.004      3.967      0.000       0.007       0.021\n",
      "AT*V           0.0125      0.003      4.002      0.000       0.006       0.019\n",
      "AT*AP      -6.064e-05      0.004     -0.017      0.987      -0.007       0.007\n",
      "AT*RH         -0.0069      0.002     -3.948      0.000      -0.010      -0.003\n",
      "V2            -0.0011      0.001     -1.207      0.227      -0.003       0.001\n",
      "V*AP           0.0042      0.002      2.399      0.016       0.001       0.008\n",
      "V*RH           0.0005      0.001      0.679      0.497      -0.001       0.002\n",
      "AP2           -0.0081      0.001     -5.935      0.000      -0.011      -0.005\n",
      "AP*RH         -0.0043      0.001     -4.299      0.000      -0.006      -0.002\n",
      "RH2           -0.0020      0.000     -6.372      0.000      -0.003      -0.001\n",
      "==============================================================================\n",
      "Omnibus:                     1240.659   Durbin-Watson:                   1.999\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             9813.162\n",
      "Skew:                          -0.667   Prob(JB):                         0.00\n",
      "Kurtosis:                       8.778   Cond. No.                     2.89e+10\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The condition number is large, 2.89e+10. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n",
      "The y_train_predicted_new with the new model is : \n",
      "       y_train_predicted_new\n",
      "0                476.883794\n",
      "1                444.701989\n",
      "2                471.427731\n",
      "3                455.066345\n",
      "4                463.420618\n",
      "...                     ...\n",
      "6692             440.548604\n",
      "6693             486.169880\n",
      "6694             438.523454\n",
      "6695             473.172090\n",
      "6696             434.660490\n",
      "\n",
      "[6697 rows x 1 columns]\n",
      "The y_test_predicted_new with the new model is : \n",
      "       y_test_predicted_new\n",
      "0               430.456744\n",
      "1               451.888075\n",
      "2               481.925668\n",
      "3               434.316465\n",
      "4               466.337309\n",
      "...                    ...\n",
      "2866            454.417742\n",
      "2867            469.097320\n",
      "2868            465.374949\n",
      "2869            436.919832\n",
      "2870            465.054122\n",
      "\n",
      "[2871 rows x 1 columns]\n",
      "The MSE_train_new with the new model is : \n",
      " 18.07308565608534\n",
      "The MSE_test_new with the new model is : \n",
      " 18.314831156556888\n",
      "The new intercept is : \n",
      " -10467.212363052022\n",
      "The coefficients of the new model, in that order is : \n",
      " [-2.34094434e+00 -4.51983541e-01  2.11636719e+01  5.67228351e+00\n",
      "  1.65007981e-02  7.56127074e-03 -7.17123388e-03 -1.01974263e-02\n",
      " -5.28200607e-03 -2.07914262e-03]\n",
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                     PE   R-squared:                       0.938\n",
      "Model:                            OLS   Adj. R-squared:                  0.938\n",
      "Method:                 Least Squares   F-statistic:                 1.020e+04\n",
      "Date:                Sun, 11 Oct 2020   Prob (F-statistic):               0.00\n",
      "Time:                        21:46:44   Log-Likelihood:                -19195.\n",
      "No. Observations:                6697   AIC:                         3.841e+04\n",
      "Df Residuals:                    6686   BIC:                         3.849e+04\n",
      "Df Model:                          10                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const      -1.047e+04   1094.926     -9.560      0.000   -1.26e+04   -8320.808\n",
      "AT            -2.3409      0.101    -23.291      0.000      -2.538      -2.144\n",
      "V             -0.4520      0.032    -14.242      0.000      -0.514      -0.390\n",
      "AP            21.1637      2.166      9.773      0.000      16.919      25.409\n",
      "RH             5.6723      0.776      7.313      0.000       4.152       7.193\n",
      "AT2            0.0165      0.002      7.279      0.000       0.012       0.021\n",
      "AT*V           0.0076      0.001      5.216      0.000       0.005       0.010\n",
      "AT*RH         -0.0072      0.001     -8.171      0.000      -0.009      -0.005\n",
      "AP2           -0.0102      0.001     -9.520      0.000      -0.012      -0.008\n",
      "AP*RH         -0.0053      0.001     -7.042      0.000      -0.007      -0.004\n",
      "RH2           -0.0021      0.000     -7.405      0.000      -0.003      -0.002\n",
      "==============================================================================\n",
      "Omnibus:                     1244.986   Durbin-Watson:                   1.999\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             9540.368\n",
      "Skew:                          -0.680   Prob(JB):                         0.00\n",
      "Kurtosis:                       8.687   Cond. No.                     2.17e+10\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The condition number is large, 2.17e+10. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nA few notes in summary -\\n\\nThe new model has all p values zero making all the predictors relevant and statistically significant.\\n\\nAs the model takes in random test and train data sets in every single run of the \\nprogram due to train_test_split command in regards with the MSE we say the following -\\n\\nMSE train and test, both for the old and the new model is found to be around 17-18\\n\\nThus MSE for both models, for both the test and the training data sets, was about same\\nthroughout in most program runs I found.\\n\\nMSE_train, MSE_test for new and old model around 17-18\\n\\nNote that MSE for the normal multi-regression model was around 20\\n\\nThus in terms of MSE both these models perform better than the normal multi-regression model\\n\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Fri Sep 25 08:31:50 2020\n",
    "\n",
    "@author: DHRUV\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "HW2\n",
    "h\n",
    "\"\"\"\n",
    "\n",
    "\"\"\"\n",
    "Assumptions\n",
    "\n",
    "All interaction terms will be assumed to be only of order 2. We'll train and test first the model\n",
    "that includes all interactions, all square terms in addition with the original terms.\n",
    "\n",
    "Normal Terms = 4\n",
    "Squared Terms = 4\n",
    "Interaction Terms = 6\n",
    "Total predictor terms = 14\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import statsmodels.api as sm\n",
    "from scipy.stats import t\n",
    "from statsmodels.tools.eval_measures import mse\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "df = pd.read_csv('Power_Plant.csv')\n",
    "print(df)\n",
    "y = df['PE']\n",
    "print(y)\n",
    "poly = PolynomialFeatures(degree=2)\n",
    "df_features = df.drop(columns = ['PE'])\n",
    "print(df_features)\n",
    "df_modified_features = pd.DataFrame(poly.fit_transform(df_features))\n",
    "print(df_modified_features)\n",
    "final_features = df_modified_features.drop(columns = 0)\n",
    "print(final_features)\n",
    "final_features.columns = ['AT', 'V', 'AP', 'RH', 'AT2', 'AT*V', 'AT*AP','AT*RH','V2','V*AP','V*RH','AP2','AP*RH','RH2']\n",
    "print(final_features)\n",
    "final_features['PE'] = y\n",
    "final_features_appended = final_features\n",
    "print(final_features_appended)\n",
    "features_appended_train, features_appended_test = train_test_split(final_features_appended, train_size = 0.7)\n",
    "print(features_appended_train)\n",
    "print(features_appended_test)\n",
    "features_appended_train.reset_index(drop=True, inplace=True)\n",
    "features_appended_test.reset_index(drop=True, inplace=True)\n",
    "print(features_appended_train)\n",
    "print(features_appended_test)\n",
    "features_train = features_appended_train.drop(columns = ['PE'])\n",
    "features_test = features_appended_test.drop(columns = ['PE'])\n",
    "y_train = features_appended_train['PE']\n",
    "y_test = features_appended_test['PE']\n",
    "print('The randomly selected 70% training features dataset is : \\n', features_train)\n",
    "print('The randomly selected 30% test feature dataset is : \\n', features_test)\n",
    "print('The randomly selected (training feature corresponding) 70% training output is : \\n',y_train)\n",
    "print('The randomly selected (test feature corresponding) 30% test output is : \\n',y_test)\n",
    "\n",
    "\"\"\"\n",
    "The above code selects random test and train features and outputs, making sure that\n",
    "features and outputs still correspond to each other. The reason being, before being\n",
    "shuffled the output column was appended back. Then random shuffling and selection was done.\n",
    "Then features and outputs again extracted, after again the row index was reset\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "reg = LinearRegression()\n",
    "reg.fit(features_train,y_train)\n",
    "y_train_predicted = reg.predict(features_train)\n",
    "y_test_predicted = reg.predict(features_test)\n",
    "MSE_train = mean_squared_error(y_train,y_train_predicted)\n",
    "MSE_test = mean_squared_error(y_test,y_test_predicted)\n",
    "\n",
    "print('The y_train_predicted is : \\n',pd.DataFrame(y_train_predicted,columns =['y_train_predicted']))\n",
    "print('The y_test_predicted is : \\n',pd.DataFrame(y_test_predicted,columns=['y_test_predicted']))\n",
    "print('The MSE_train is : \\n',MSE_train)\n",
    "print('The MSE_test is : \\n',MSE_test)\n",
    "\n",
    "print('The intercept obtained for this model is : \\n',reg.intercept_)\n",
    "print('The coefficients obtained for the predictors in an array in their respective order is : \\n',reg.coef_)\n",
    "\n",
    "features_train_sm = sm.add_constant(features_train)      \n",
    "est = sm.OLS(y_train, features_train_sm)\n",
    "est_data = est.fit()\n",
    "print(est_data.summary())\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "Few points to note -\n",
    "\n",
    "statsmodels, used to obtain the overall data summary, obtains this summary over the training\n",
    "data. It is given the y_train and features_train, and used the predicted y for the training data\n",
    "against the actual y_train and the features_train to obtain various statistics. We'll assume\n",
    "this doesn't affect our analysis or our results much.\n",
    "\n",
    "As the test and train sets are randomly generated, there is some disparity over different\n",
    "test and train sets, in terms of evaluated model parameters and various other quantities.\n",
    "\n",
    "Despite this minor disparities the following behaviour was consistent (given p boundary is\n",
    "0.05 corresponding to 95% confidence interval) -\n",
    "\n",
    "AT, V, AT*AP, V2, V*AP, V*RH all had large p values, beyond p boundary at 0.05\n",
    "\n",
    "Thus they should be removed\n",
    "\n",
    "However AT, V have relevant interaction terms. Thus via hierarchical principle those terms/predictors\n",
    "can't be removed from the model.\n",
    "\n",
    "Thus, we'll remove the following : AT*AP, V2, V*AP, V*RH\n",
    "\n",
    "And we'll keep the rest predictors\n",
    "\n",
    "\n",
    "Summary : AT*AP, V2, V*AP, V*RH are removed\n",
    "AT, V due to hierarchical principle stay in\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "features_train_new = features_train.drop(columns = ['AT*AP','V2','V*AP','V*RH'])\n",
    "features_test_new = features_test.drop(columns = ['AT*AP','V2','V*AP','V*RH'])\n",
    "\n",
    "\"\"\"\n",
    "y_train and y_test obviously stay the same\n",
    "\n",
    "\"\"\"\n",
    "reg_new = LinearRegression()\n",
    "\n",
    "reg_new.fit(features_train_new,y_train)\n",
    "y_train_predicted_new = reg_new.predict(features_train_new)\n",
    "y_test_predicted_new = reg_new.predict(features_test_new)\n",
    "MSE_train_new = mean_squared_error(y_train,y_train_predicted_new)\n",
    "MSE_test_new = mean_squared_error(y_test,y_test_predicted_new)\n",
    "\n",
    "print('The y_train_predicted_new with the new model is : \\n', pd.DataFrame(y_train_predicted_new,columns=['y_train_predicted_new']))\n",
    "print('The y_test_predicted_new with the new model is : \\n',pd.DataFrame(y_test_predicted_new,columns=['y_test_predicted_new']))\n",
    "print('The MSE_train_new with the new model is : \\n',MSE_train_new)\n",
    "print('The MSE_test_new with the new model is : \\n', MSE_test_new)\n",
    "\n",
    "print('The new intercept is : \\n',reg_new.intercept_)\n",
    "print('The coefficients of the new model, in that order is : \\n', reg_new.coef_)\n",
    "\n",
    "features_train_new_sm = sm.add_constant(features_train_new)      \n",
    "est_new = sm.OLS(y_train, features_train_new_sm)\n",
    "est_data_new = est_new.fit()\n",
    "print(est_data_new.summary())\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "A few notes in summary -\n",
    "\n",
    "The new model has all p values zero making all the predictors relevant and statistically significant.\n",
    "\n",
    "As the model takes in random test and train data sets in every single run of the \n",
    "program due to train_test_split command in regards with the MSE we say the following -\n",
    "\n",
    "MSE train and test, both for the old and the new model is found to be around 17-18\n",
    "\n",
    "Thus MSE for both models, for both the test and the training data sets, was about same\n",
    "throughout in most program runs I found.\n",
    "\n",
    "MSE_train, MSE_test for new and old model around 17-18\n",
    "\n",
    "Note that MSE for the normal multi-regression model was around 20\n",
    "\n",
    "Thus in terms of MSE both these models perform better than the normal multi-regression model\n",
    "\n",
    "\"\"\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
