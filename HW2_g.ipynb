{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         AT      V       AP     RH      PE\n",
      "0     14.96  41.76  1024.07  73.17  463.26\n",
      "1     25.18  62.96  1020.04  59.08  444.37\n",
      "2      5.11  39.40  1012.16  92.14  488.56\n",
      "3     20.86  57.32  1010.24  76.64  446.48\n",
      "4     10.82  37.50  1009.23  96.62  473.90\n",
      "...     ...    ...      ...    ...     ...\n",
      "9563  16.65  49.69  1014.01  91.00  460.03\n",
      "9564  13.19  39.18  1023.67  66.78  469.62\n",
      "9565  31.32  74.33  1012.92  36.48  429.57\n",
      "9566  24.48  69.45  1013.86  62.39  435.74\n",
      "9567  21.60  62.52  1017.23  67.87  453.28\n",
      "\n",
      "[9568 rows x 5 columns]\n",
      "         AT      V       AP     RH\n",
      "0     14.96  41.76  1024.07  73.17\n",
      "1     25.18  62.96  1020.04  59.08\n",
      "2      5.11  39.40  1012.16  92.14\n",
      "3     20.86  57.32  1010.24  76.64\n",
      "4     10.82  37.50  1009.23  96.62\n",
      "...     ...    ...      ...    ...\n",
      "9563  16.65  49.69  1014.01  91.00\n",
      "9564  13.19  39.18  1023.67  66.78\n",
      "9565  31.32  74.33  1012.92  36.48\n",
      "9566  24.48  69.45  1013.86  62.39\n",
      "9567  21.60  62.52  1017.23  67.87\n",
      "\n",
      "[9568 rows x 4 columns]\n",
      "        0      1      2        3      4          5           6          7  \\\n",
      "0     1.0  14.96  41.76  1024.07  73.17   624.7296  15320.0872  1094.6232   \n",
      "1     1.0  25.18  62.96  1020.04  59.08  1585.3328  25684.6072  1487.6344   \n",
      "2     1.0   5.11  39.40  1012.16  92.14   201.3340   5172.1376   470.8354   \n",
      "3     1.0  20.86  57.32  1010.24  76.64  1195.6952  21073.6064  1598.7104   \n",
      "4     1.0  10.82  37.50  1009.23  96.62   405.7500  10919.8686  1045.4284   \n",
      "...   ...    ...    ...      ...    ...        ...         ...        ...   \n",
      "9563  1.0  16.65  49.69  1014.01  91.00   827.3385  16883.2665  1515.1500   \n",
      "9564  1.0  13.19  39.18  1023.67  66.78   516.7842  13502.2073   880.8282   \n",
      "9565  1.0  31.32  74.33  1012.92  36.48  2328.0156  31724.6544  1142.5536   \n",
      "9566  1.0  24.48  69.45  1013.86  62.39  1700.1360  24819.2928  1527.3072   \n",
      "9567  1.0  21.60  62.52  1017.23  67.87  1350.4320  21972.1680  1465.9920   \n",
      "\n",
      "               8          9          10  \n",
      "0     42765.1632  3055.5792  74931.2019  \n",
      "1     64221.7184  3719.6768  60263.9632  \n",
      "2     39879.1040  3630.3160  93260.4224  \n",
      "3     57906.9568  4393.0048  77424.7936  \n",
      "4     37846.1250  3623.2500  97511.8026  \n",
      "...          ...        ...         ...  \n",
      "9563  50386.1569  4521.7900  92274.9100  \n",
      "9564  40107.3906  2616.4404  68360.6826  \n",
      "9565  75290.3436  2711.5584  36951.3216  \n",
      "9566  70412.5770  4332.9855  63254.7254  \n",
      "9567  63597.2196  4243.2324  69039.4001  \n",
      "\n",
      "[9568 rows x 11 columns]\n",
      "         1      2        3      4          5           6          7   \\\n",
      "0     14.96  41.76  1024.07  73.17   624.7296  15320.0872  1094.6232   \n",
      "1     25.18  62.96  1020.04  59.08  1585.3328  25684.6072  1487.6344   \n",
      "2      5.11  39.40  1012.16  92.14   201.3340   5172.1376   470.8354   \n",
      "3     20.86  57.32  1010.24  76.64  1195.6952  21073.6064  1598.7104   \n",
      "4     10.82  37.50  1009.23  96.62   405.7500  10919.8686  1045.4284   \n",
      "...     ...    ...      ...    ...        ...         ...        ...   \n",
      "9563  16.65  49.69  1014.01  91.00   827.3385  16883.2665  1515.1500   \n",
      "9564  13.19  39.18  1023.67  66.78   516.7842  13502.2073   880.8282   \n",
      "9565  31.32  74.33  1012.92  36.48  2328.0156  31724.6544  1142.5536   \n",
      "9566  24.48  69.45  1013.86  62.39  1700.1360  24819.2928  1527.3072   \n",
      "9567  21.60  62.52  1017.23  67.87  1350.4320  21972.1680  1465.9920   \n",
      "\n",
      "              8          9           10  \n",
      "0     42765.1632  3055.5792  74931.2019  \n",
      "1     64221.7184  3719.6768  60263.9632  \n",
      "2     39879.1040  3630.3160  93260.4224  \n",
      "3     57906.9568  4393.0048  77424.7936  \n",
      "4     37846.1250  3623.2500  97511.8026  \n",
      "...          ...        ...         ...  \n",
      "9563  50386.1569  4521.7900  92274.9100  \n",
      "9564  40107.3906  2616.4404  68360.6826  \n",
      "9565  75290.3436  2711.5584  36951.3216  \n",
      "9566  70412.5770  4332.9855  63254.7254  \n",
      "9567  63597.2196  4243.2324  69039.4001  \n",
      "\n",
      "[9568 rows x 10 columns]\n",
      "         AT      V       AP     RH       AT*V       AT*AP      AT*RH  \\\n",
      "0     14.96  41.76  1024.07  73.17   624.7296  15320.0872  1094.6232   \n",
      "1     25.18  62.96  1020.04  59.08  1585.3328  25684.6072  1487.6344   \n",
      "2      5.11  39.40  1012.16  92.14   201.3340   5172.1376   470.8354   \n",
      "3     20.86  57.32  1010.24  76.64  1195.6952  21073.6064  1598.7104   \n",
      "4     10.82  37.50  1009.23  96.62   405.7500  10919.8686  1045.4284   \n",
      "...     ...    ...      ...    ...        ...         ...        ...   \n",
      "9563  16.65  49.69  1014.01  91.00   827.3385  16883.2665  1515.1500   \n",
      "9564  13.19  39.18  1023.67  66.78   516.7842  13502.2073   880.8282   \n",
      "9565  31.32  74.33  1012.92  36.48  2328.0156  31724.6544  1142.5536   \n",
      "9566  24.48  69.45  1013.86  62.39  1700.1360  24819.2928  1527.3072   \n",
      "9567  21.60  62.52  1017.23  67.87  1350.4320  21972.1680  1465.9920   \n",
      "\n",
      "            V*AP       V*RH       AP*RH  \n",
      "0     42765.1632  3055.5792  74931.2019  \n",
      "1     64221.7184  3719.6768  60263.9632  \n",
      "2     39879.1040  3630.3160  93260.4224  \n",
      "3     57906.9568  4393.0048  77424.7936  \n",
      "4     37846.1250  3623.2500  97511.8026  \n",
      "...          ...        ...         ...  \n",
      "9563  50386.1569  4521.7900  92274.9100  \n",
      "9564  40107.3906  2616.4404  68360.6826  \n",
      "9565  75290.3436  2711.5584  36951.3216  \n",
      "9566  70412.5770  4332.9855  63254.7254  \n",
      "9567  63597.2196  4243.2324  69039.4001  \n",
      "\n",
      "[9568 rows x 10 columns]\n",
      "0       463.26\n",
      "1       444.37\n",
      "2       488.56\n",
      "3       446.48\n",
      "4       473.90\n",
      "         ...  \n",
      "9563    460.03\n",
      "9564    469.62\n",
      "9565    429.57\n",
      "9566    435.74\n",
      "9567    453.28\n",
      "Name: PE, Length: 9568, dtype: float64\n",
      "The y predicted using all the interaction terms is as follows : \n",
      "       y_predicted\n",
      "0      466.615071\n",
      "1      444.649552\n",
      "2      486.971524\n",
      "3      448.816541\n",
      "4      474.900683\n",
      "...           ...\n",
      "9563   457.940003\n",
      "9564   471.906431\n",
      "9565   436.415620\n",
      "9566   442.569945\n",
      "9567   448.522476\n",
      "\n",
      "[9568 rows x 1 columns]\n",
      "The mean squared error obtained for this interaction based model is : \n",
      " 18.55106888539469\n",
      "The value of intercept term for this model is : \n",
      " 685.7824681478685\n",
      "The value of the feature coefficients in array form for all the terms, including interaction terms is, in their respective order : \n",
      " [-4.34701412e+00 -7.67485763e+00 -1.52354642e-01  1.57090705e+00\n",
      "  2.09709231e-02  1.75904518e-03 -5.23035364e-03  6.81235433e-03\n",
      "  8.38633179e-04 -1.61179894e-03]\n",
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                     PE   R-squared:                       0.936\n",
      "Model:                            OLS   Adj. R-squared:                  0.936\n",
      "Method:                 Least Squares   F-statistic:                 1.405e+04\n",
      "Date:                Sun, 11 Oct 2020   Prob (F-statistic):               0.00\n",
      "Time:                        21:47:36   Log-Likelihood:                -27548.\n",
      "No. Observations:                9568   AIC:                         5.512e+04\n",
      "Df Residuals:                    9557   BIC:                         5.520e+04\n",
      "Df Model:                          10                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const        685.7825     78.640      8.721      0.000     531.631     839.934\n",
      "AT            -4.3470      2.373     -1.832      0.067      -8.999       0.305\n",
      "V             -7.6749      1.351     -5.682      0.000     -10.323      -5.027\n",
      "AP            -0.1524      0.077     -1.983      0.047      -0.303      -0.002\n",
      "RH             1.5709      0.773      2.031      0.042       0.055       3.087\n",
      "AT*V           0.0210      0.001     23.338      0.000       0.019       0.023\n",
      "AT*AP          0.0018      0.002      0.752      0.452      -0.003       0.006\n",
      "AT*RH         -0.0052      0.001     -6.444      0.000      -0.007      -0.004\n",
      "V*AP           0.0068      0.001      5.135      0.000       0.004       0.009\n",
      "V*RH           0.0008      0.000      1.716      0.086      -0.000       0.002\n",
      "AP*RH         -0.0016      0.001     -2.125      0.034      -0.003      -0.000\n",
      "==============================================================================\n",
      "Omnibus:                     1454.609   Durbin-Watson:                   2.030\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             9170.848\n",
      "Skew:                          -0.574   Prob(JB):                         0.00\n",
      "Kurtosis:                       7.657   Cond. No.                     1.70e+08\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The condition number is large, 1.7e+08. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n",
      "The reference value of t-statistic is : \n",
      " 1.9602122388658259\n",
      "The reference value for F-statistic (10,9557,0.05) is, from an online calculator : \n",
      " 1.83169\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nAnalyzing the p values with the p value boundary being 0.05 (95% confidence interval)\\n\\nAT : We can\\'t reject the null hypothesis for AT. AT not significant. Due to hiearchical principal however\\nwe still can\\'t remove it from the model.\\n\\nV : Significant. Present in a significant interaction.\\n\\nAP : Barely, just barely significant. At the boundary seperating significant predictor, from the \\ninsignificant predictor. But taking p = 0.05, 0.047 < 0.05 and thus we declare it significant and\\nreject the null hypothesis for AP. Again it is present in an interaction that is significant.\\n\\nRH : Again barely significant. As 0.042 < 0.05, we declare it significant and reject the null. Also\\npresent in an interaction that\\'s significant.\\n\\nAT*V : Significant\\n\\nAT*AP : Null hypothesis cannot be rejected. Insignificant.\\n\\nAT*RH : Significant\\n\\nV*AP : Significant\\n\\nV*RH : Insignificant. Null can\\'t be rejected.\\n\\nAP*RH : Significant. 0.034 < 0.05 so null can be rejected.\\n\\n\\nF-statistic implies total null hypothesis can be rejected, making at least one predictor relevant\\n\\n\\n\\n\\nSummarizing :\\n\\nIndividually in our interaction based model, \\nV, AP, RH significant  \\n\\nInteraction terms,\\nAT*V , AT*RH, V*AP, AP*RH are significant\\n\\nThus interactions between AT and V, AT and RH, V and AP, AP and RH must be considered in the model\\n\\nAT is individually insignificant\\nAT*AP , V*RH interaction terms are insignificant and can be removed from the model\\n\\n\\nHIEARCHICAL PRINCIPLE states that despite large p-values for AT, it should be included in the\\nmodel. The reason being AT*V and V both are included. Thus given that AT is included in an interaction, and \\nthat interaction has a low p-value, or the interaction is relevant, the terms individually included\\nin the interaction must be included in the model (even if they have high p-values).\\n\\nTHUS,\\nAT cannot be removed from the model despite it\\'s p-value being large. So even though AT is statistically\\ninsignificant, it\\'s presence in interaction terms that are significant implies via the hiearchical principle\\nthat it\\'s presence is crucial to \"correctly interpret\" the model.\\n\\nTHUS all the interaction based terms with large p can be dropped, however the main terms, the terms\\nthat are originally present, can\\'t be dropped even if their p values are high, if those terms are\\npresent in interactions that are relevant.\\n\\nSimilar discussions for other terms can be done\\n\\nWe do need test data however to validate whether or not including all the relevant interaction terms\\nmakes the model better or not. As such, the MSE difference between the normal multi-regression model\\nand the interaction based multi-regression model, does not truly warrant the inclusion of 6 more \\npredictors other than only to get a more detailed look at the model. In terms of prediction, at least \\naccording to training data, normal multi-regression model is pretty accurate.\\n\\nWith available test data and prediction on it however, and the errors we obtain on its predictions, we can \\ndecide better which model of the two is more suitable.\\n\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Fri Sep 25 05:14:32 2020\n",
    "\n",
    "@author: DHRUV\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "HW2\n",
    "g\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\"\"\"\n",
    "Assumption\n",
    "We have to run a full linear regression model with ALL pairwise interaction terms (in HW2 PDF)\n",
    "Thus we'll run a single model with all the terms present, and all the pairwise interactions also\n",
    "present and test their relevance/significance using p/t tests. So only a single model will be run\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\"\"\"\n",
    "Model Type\n",
    "There will be:\n",
    "AT    V    AP    RH        AT*V          AT*AP       AT*RH        V*AP       V*RH        AP*RH\n",
    "\n",
    "So 4 single terms and 6 interaction terms for a total of 10 terms\n",
    "Thus we have 10 predictors in this model predicting PE\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import statsmodels.api as sm\n",
    "from scipy.stats import t\n",
    "from statsmodels.tools.eval_measures import mse\n",
    "\n",
    "df = pd.read_csv('Power_Plant.csv')\n",
    "print(df)\n",
    "poly = PolynomialFeatures(degree=2, interaction_only = True)\n",
    "df_features = df.drop(columns = ['PE'])\n",
    "print(df_features)\n",
    "df_modified_features = pd.DataFrame(poly.fit_transform(df_features))\n",
    "print(df_modified_features)\n",
    "final_features = df_modified_features.drop(columns = 0)\n",
    "print(final_features)\n",
    "final_features.columns = ['AT','V','AP','RH','AT*V','AT*AP','AT*RH','V*AP','V*RH','AP*RH']\n",
    "print(final_features)\n",
    "y = df['PE']\n",
    "print(y)\n",
    "reg = LinearRegression()\n",
    "reg.fit(final_features,y)\n",
    "y_predicted = reg.predict(final_features)\n",
    "print('The y predicted using all the interaction terms is as follows : \\n', pd.DataFrame(y_predicted, columns=['y_predicted']))\n",
    "print('The mean squared error obtained for this interaction based model is : \\n', mean_squared_error(y,y_predicted))\n",
    "print('The value of intercept term for this model is : \\n', reg.intercept_)\n",
    "print('The value of the feature coefficients in array form for all the terms, including interaction terms is, in their respective order : \\n', reg.coef_)\n",
    "\n",
    "\"\"\"\n",
    "The MSE for the multi-regression model was around 20\n",
    "The MSE for this interaction based multi-regression model is 18\n",
    "Thus there is a minor improvement in the prediction of the model in terms of the MSE error\n",
    "\n",
    "Again, test data needs to be considered for a much better interpretation and for complete analysis\n",
    "\n",
    "\"\"\"\n",
    "final_features_sm = sm.add_constant(final_features)      \n",
    "est = sm.OLS(y, final_features_sm)\n",
    "est_data = est.fit()\n",
    "print(est_data.summary())\n",
    "t_reference = t.ppf(1-0.025, 9557)\n",
    "print('The reference value of t-statistic is : \\n',t_reference)\n",
    "print('The reference value for F-statistic (10,9557,0.05) is, from an online calculator : \\n 1.83169')\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Analyzing the p values with the p value boundary being 0.05 (95% confidence interval)\n",
    "\n",
    "AT : We can't reject the null hypothesis for AT. AT not significant. Due to hiearchical principal however\n",
    "we still can't remove it from the model.\n",
    "\n",
    "V : Significant. Present in a significant interaction.\n",
    "\n",
    "AP : Barely, just barely significant. At the boundary seperating significant predictor, from the \n",
    "insignificant predictor. But taking p = 0.05, 0.047 < 0.05 and thus we declare it significant and\n",
    "reject the null hypothesis for AP. Again it is present in an interaction that is significant.\n",
    "\n",
    "RH : Again barely significant. As 0.042 < 0.05, we declare it significant and reject the null. Also\n",
    "present in an interaction that's significant.\n",
    "\n",
    "AT*V : Significant\n",
    "\n",
    "AT*AP : Null hypothesis cannot be rejected. Insignificant.\n",
    "\n",
    "AT*RH : Significant\n",
    "\n",
    "V*AP : Significant\n",
    "\n",
    "V*RH : Insignificant. Null can't be rejected.\n",
    "\n",
    "AP*RH : Significant. 0.034 < 0.05 so null can be rejected.\n",
    "\n",
    "\n",
    "F-statistic implies total null hypothesis can be rejected, making at least one predictor relevant\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Summarizing :\n",
    "\n",
    "Individually in our interaction based model, \n",
    "V, AP, RH significant  \n",
    "\n",
    "Interaction terms,\n",
    "AT*V , AT*RH, V*AP, AP*RH are significant\n",
    "\n",
    "Thus interactions between AT and V, AT and RH, V and AP, AP and RH must be considered in the model\n",
    "\n",
    "AT is individually insignificant\n",
    "AT*AP , V*RH interaction terms are insignificant and can be removed from the model\n",
    "\n",
    "\n",
    "HIEARCHICAL PRINCIPLE states that despite large p-values for AT, it should be included in the\n",
    "model. The reason being AT*V and V both are included. Thus given that AT is included in an interaction, and \n",
    "that interaction has a low p-value, or the interaction is relevant, the terms individually included\n",
    "in the interaction must be included in the model (even if they have high p-values).\n",
    "\n",
    "THUS,\n",
    "AT cannot be removed from the model despite it's p-value being large. So even though AT is statistically\n",
    "insignificant, it's presence in interaction terms that are significant implies via the hiearchical principle\n",
    "that it's presence is crucial to \"correctly interpret\" the model.\n",
    "\n",
    "THUS all the interaction based terms with large p can be dropped, however the main terms, the terms\n",
    "that are originally present, can't be dropped even if their p values are high, if those terms are\n",
    "present in interactions that are relevant.\n",
    "\n",
    "Similar discussions for other terms can be done\n",
    "\n",
    "We do need test data however to validate whether or not including all the relevant interaction terms\n",
    "makes the model better or not. As such, the MSE difference between the normal multi-regression model\n",
    "and the interaction based multi-regression model, does not truly warrant the inclusion of 6 more \n",
    "predictors other than only to get a more detailed look at the model. In terms of prediction, at least \n",
    "according to training data, normal multi-regression model is pretty accurate.\n",
    "\n",
    "With available test data and prediction on it however, and the errors we obtain on its predictions, we can \n",
    "decide better which model of the two is more suitable.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
